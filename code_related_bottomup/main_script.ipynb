{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lijingjie/ljj/local/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "import os.path\n",
    "import ow_f01, ow_train, ow_predict, predict_mean\n",
    "import pickle\n",
    "from code.refactor.common import loadSettingsFromYamlFile,save_object\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'tmp/data/shishang/'\n",
    "result_path = 'tmp/data/shishang/test_0705'\n",
    "suffix = '.da'\n",
    "item = 'p1'\n",
    "for_what = ['train', 'predict']\n",
    "cate = 2584\n",
    "\n",
    "scenarioSettingsPath = 'code/refactor/ow_scenario.yaml'\n",
    "scenario = loadSettingsFromYamlFile(scenarioSettingsPath)\n",
    "area_rdc_map = pd.read_csv('/home/ubuntu/yulong/promotion_offline/tmp/ow_deploy_single/area_rdc_mapping.csv')\n",
    "holidays_df=pd.read_csv('/home/ubuntu/yulong/promotion_offline/tmp/ow_deploy_single/holidays.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df_mem_usage(df):\n",
    "    # memery now\n",
    "    start_mem_usg = df.memory_usage().sum() / 1024 ** 2\n",
    "    print(\"Memory usage of the dataframe is :\", start_mem_usg, \"MB\")\n",
    "    \n",
    "    #np.nan will be handled as float\n",
    "    NAlist = []\n",
    "    for col in df.columns:\n",
    "        # filter object type\n",
    "        if (df[col].dtypes == np.float64):\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "            continue\n",
    "        if (df[col].dtypes != object)&(df[col].dtypes != 'datetime64[ns]'):\n",
    "            \n",
    "            print(\"**************************\")\n",
    "            print(\"columns: %s\"%col)\n",
    "            print(\"dtype before: %s\"%df[col].dtype)\n",
    "            \n",
    "            # if int or not\n",
    "            isInt = False\n",
    "            mmax = df[col].max()\n",
    "            mmin = df[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore Na needs to be filled\n",
    "            if not np.isfinite(df[col]).all():\n",
    "                NAlist.append(col)\n",
    "                #continue\n",
    "                df[col].fillna(-999, inplace=True) # fill -999\n",
    "                \n",
    "            # test if column can be converted to an integer\n",
    "            asint = df[col].fillna(0).astype(np.int64)\n",
    "            result = np.fabs(df[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result < 0.01: # absolute error < 0.01,then could be saw as integer\n",
    "                isInt = True\n",
    "            \n",
    "            # make interger / unsigned Integer datatypes\n",
    "            if isInt:\n",
    "                if mmin >= 0: # min>=0, then unsigned integer\n",
    "                    if mmax <= np.iinfo(np.uint8).max:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif mmax <= np.iinfo(np.uint16).max:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif mmax <= np.iinfo(np.uint32).max:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mmin > np.iinfo(np.int8).min and mmax < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif mmin > np.iinfo(np.int16).min and mmax < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif mmin > np.iinfo(np.int32).min and mmax < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif mmin > np.iinfo(np.int64).min and mmax < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "            df.replace(-999, np.nan, inplace=True)\n",
    "            print(\"dtype after: %s\"%df[col].dtype)\n",
    "            print(\"********************************\")\n",
    "    print(\"___MEMORY USAGE AFTER CONVERSION:___\")\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return df, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_used_header=['productkey', 'promotionkey', 'startdatetime', 'enddatetime', 'jdprice', 'syntheticgrossprice', 'promotiondesc', 'promotiondesc_flag', 'promotiontype', 'promotionsubtype',\n",
    "                'areatypearray', 'tokenflag', 'directdiscount_discount', 'directdiscount_availabilitynumber', 'bundle_subtype1_threshold', 'bundle_subtype1_giveaway',\n",
    "                'bundle_subtype4_threshold1', 'bundle_subtype4_giveaway1', 'bundle_subtype4_threshold2', 'bundle_subtype4_giveaway2', 'bundle_subtype4_threshold3',\n",
    "                'bundle_subtype4_giveaway3', 'bundle_subtype2_threshold', 'bundle_subtype2_giveaway', 'bundle_subtype2_maximumgiveaway', 'bundle_subtype15_thresholdnumber1',\n",
    "                'bundle_subtype15_giveawayrate1', 'bundle_subtype15_thresholdnumber2', 'bundle_subtype15_giveawayrate2', 'bundle_subtype15_thresholdnumber3',\n",
    "                'bundle_subtype15_giveawayrate3', 'bundle_subtype6_thresholdnumber', 'bundle_subtype6_freenumber', 'suit_maxvaluepool', 'suit_minvaluepool', 'suit_avgvaluepool',\n",
    "                'suit_discount', 'directdiscount_saleprice', 'bundle_subtype1_percent', 'bundle_subtype4_percent', 'bundle_subtype2_percent', 'bundle_subtype15_percent',\n",
    "                'bundle_subtype6_percent', 'suit_percent', 'allpercentdiscount', 'mainproductkey', 'hierarchylevel3key', 'createdate', 'statuscode', 'dt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\thyperparameters\n",
    "'''\n",
    "cate = 2584\n",
    "pred_date = pd.to_datetime('2018-05-07')\n",
    "scenario['lookforwardPeriodDays'] = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output and save: 2584_p1_train\n",
      "convert to Float columns:\n",
      "allpercentdiscount\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate1\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate2\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate3\n",
      "convert to Float columns:\n",
      "bundle_subtype15_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber1\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber2\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber3\n",
      "convert to Float columns:\n",
      "bundle_subtype1_giveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype1_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype1_threshold\n",
      "convert to Float columns:\n",
      "bundle_subtype2_giveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype2_maximumgiveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype2_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype2_threshold\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway1\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway2\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway3\n",
      "convert to Float columns:\n",
      "bundle_subtype4_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold1\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold2\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold3\n",
      "convert to Float columns:\n",
      "bundle_subtype6_freenumber\n",
      "convert to Float columns:\n",
      "bundle_subtype6_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype6_thresholdnumber\n",
      "convert to Float columns:\n",
      "directdiscount_availabilitynumber\n",
      "convert to Float columns:\n",
      "directdiscount_discount\n",
      "convert to Float columns:\n",
      "directdiscount_saleprice\n",
      "convert to Float columns:\n",
      "hierarchylevel3key\n",
      "convert to Float columns:\n",
      "jdprice\n",
      "convert to Float columns:\n",
      "mainproductkey\n",
      "convert to Float columns:\n",
      "productkey\n",
      "convert to Float columns:\n",
      "promotionkey\n",
      "convert to Float columns:\n",
      "promotionsubtype\n",
      "convert to Float columns:\n",
      "promotiontype\n",
      "convert to Float columns:\n",
      "statuscode\n",
      "convert to Float columns:\n",
      "suit_avgvaluepool\n",
      "convert to Float columns:\n",
      "suit_discount\n",
      "convert to Float columns:\n",
      "suit_maxvaluepool\n",
      "convert to Float columns:\n",
      "suit_minvaluepool\n",
      "convert to Float columns:\n",
      "suit_percent\n",
      "convert to Float columns:\n",
      "syntheticgrossprice\n",
      "('| - Before filter: ', 1002561)\n",
      "('| - Filtered tokens: ', 1000791)\n",
      "('| - Filtered descriptions: ', 999071)\n",
      "('| - Filtered flash sale available units', 998985)\n",
      "('| - Filtered non-national promo: ', 998939)\n",
      "| | - Add additional columns\n",
      "| | - Calculate dd price per promotion\n",
      "| | - Calculate dd price per period\n",
      "| | - Generate bundle features\n",
      "| | - Calculate bundle price per period\n",
      "| - Reformat date\n",
      "| | - process features\n",
      "| | - aggregate features per period\n",
      "| | - prep data for Step 3\n",
      "| | - fix indicators on days with end time 00:00 or start time 23:59\n",
      "| | - calculate weighted price per day\n",
      "| | - aggregate features per day\n",
      "f01 shape\n",
      "(6326406, 23)\n",
      "output and save: 2584_p1_predict\n",
      "convert to Float columns:\n",
      "allpercentdiscount\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate1\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate2\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate3\n",
      "convert to Float columns:\n",
      "bundle_subtype15_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber1\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber2\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber3\n",
      "convert to Float columns:\n",
      "bundle_subtype1_giveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype1_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype1_threshold\n",
      "convert to Float columns:\n",
      "bundle_subtype2_giveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype2_maximumgiveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype2_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype2_threshold\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway1\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway2\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway3\n",
      "convert to Float columns:\n",
      "bundle_subtype4_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold1\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold2\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold3\n",
      "convert to Float columns:\n",
      "bundle_subtype6_freenumber\n",
      "convert to Float columns:\n",
      "bundle_subtype6_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype6_thresholdnumber\n",
      "convert to Float columns:\n",
      "directdiscount_availabilitynumber\n",
      "convert to Float columns:\n",
      "directdiscount_discount\n",
      "convert to Float columns:\n",
      "directdiscount_saleprice\n",
      "convert to Float columns:\n",
      "hierarchylevel3key\n",
      "convert to Float columns:\n",
      "jdprice\n",
      "convert to Float columns:\n",
      "mainproductkey\n",
      "convert to Float columns:\n",
      "productkey\n",
      "convert to Float columns:\n",
      "promotionkey\n",
      "convert to Float columns:\n",
      "promotionsubtype\n",
      "convert to Float columns:\n",
      "promotiontype\n",
      "convert to Float columns:\n",
      "statuscode\n",
      "convert to Float columns:\n",
      "suit_avgvaluepool\n",
      "convert to Float columns:\n",
      "suit_discount\n",
      "convert to Float columns:\n",
      "suit_maxvaluepool\n",
      "convert to Float columns:\n",
      "suit_minvaluepool\n",
      "convert to Float columns:\n",
      "suit_percent\n",
      "convert to Float columns:\n",
      "syntheticgrossprice\n",
      "('| - Before filter: ', 21275)\n",
      "('| - Filtered tokens: ', 21266)\n",
      "('| - Filtered descriptions: ', 21244)\n",
      "('| - Filtered flash sale available units', 21244)\n",
      "('| - Filtered non-national promo: ', 21244)\n",
      "| | - Add additional columns\n",
      "| | - Calculate dd price per promotion\n",
      "| | - Calculate dd price per period\n",
      "| | - Generate bundle features\n",
      "| | - Calculate bundle price per period\n",
      "| - Reformat date\n",
      "| | - process features\n",
      "| | - aggregate features per period\n",
      "| | - prep data for Step 3\n",
      "| | - fix indicators on days with end time 00:00 or start time 23:59\n",
      "| | - calculate weighted price per day\n",
      "| | - aggregate features per day\n",
      "f01 shape\n",
      "(1803757, 23)\n"
     ]
    }
   ],
   "source": [
    "p1_path = os.path.join(path, str(cate)+'/'+str(cate)+'_'+item+suffix)\n",
    "period_promo_raw = pd.read_csv(p1_path,sep='\\t',header=None)\n",
    "period_promo_raw.columns=p1_used_header\n",
    "    \n",
    "for fw in for_what:\n",
    "    print \"output and save: %s_p1_%s\"%(str(cate),fw)\n",
    "    period_promo_raw_clean = period_promo_raw.copy()\n",
    "    train_pred_gate = fw   # 'train'\n",
    "    f01_output = ow_f01.generate_f01_promo(area_rdc_map, period_promo_raw_clean,scenario, train_pred_gate, ForecastStartDate=pred_date)\n",
    "    f01_output.to_csv(os.path.join(result_path, train_pred_gate+'_'+item+'_'+str(cate)+'.csv'),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality_df = pd.read_csv('tmp/data/870_season.csv', parse_dates=['Date'])\n",
    "file_path = os.path.join(path, str(cate)+'/'+str(cate)+'_'+'ts.da')\n",
    "ts_df = pd.read_csv(file_path,header=None,sep='\\t')\n",
    "\n",
    "pro_canlender_path = os.path.join(path, str(cate)+'/'+str(cate)+'_'+'p2.da')\n",
    "promoCalendarDf = pd.read_csv(pro_canlender_path,sep='\\t',header=None)\n",
    "promoCalendarDf.columns=['ProductKey', 'Date', 'HierarchyLevel3Key', 'PromotionCount', 'bundlecount', 'MaxDiscount', 'MinDiscount', 'AvgDiscount', 'MaxSyntheticDiscountA',\n",
    "\t\t\t\t         'MinSyntheticDiscountA', 'AvgSyntheticDiscountA', 'MaxBundleDiscount', 'MinBundleDiscount', 'AvgBundleDiscount', 'MaxDirectDiscount', 'MinDirectDiscount',\n",
    "\t\t\t\t         'AvgDirectDiscount', 'MaxFreegiftDiscount', 'MinFreegiftDiscount', 'AvgFreegiftDiscount', 'SyntheticGrossPrice', 'promotionkey', 'promotiontype',\n",
    "\t\t\t\t         'promotionsubtype', 'syntheticgrossprice_vb', 'jdprice', 'syntheticdiscounta_vb', 'durationinhours', 'daynumberinpromotion', 'bundleflag', 'directdiscountflag',\n",
    "\t\t\t\t         'freegiftflag', 'suitflag', 'numberproducts', 'numberhierarchylevel1', 'numberhierarchylevel2', 'numberhierarchylevel3', 'strongmark', 'stockprice', 'dt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Int columns:\n",
      "Holiday\n",
      "convert to Int columns:\n",
      "Ind_1111_pre\n",
      "convert to Int columns:\n",
      "Ind_1111\n",
      "convert to Int columns:\n",
      "Ind_1111_post\n",
      "convert to Int columns:\n",
      "Ind_618_pre\n",
      "convert to Int columns:\n",
      "Ind_618\n",
      "convert to Int columns:\n",
      "Ind_618_post\n",
      "convert to Int columns:\n",
      "Ind_1212\n",
      "convert to Float columns:\n",
      "MaxSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "MinSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "AvgSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "SyntheticGrossPrice\n",
      "convert to Float columns:\n",
      "promotionkey\n",
      "convert to Float columns:\n",
      "promotiontype\n",
      "convert to Float columns:\n",
      "promotionsubtype\n",
      "convert to Float columns:\n",
      "syntheticgrossprice_vb\n",
      "convert to Float columns:\n",
      "jdprice\n",
      "convert to Float columns:\n",
      "syntheticdiscounta_vb\n",
      "convert to Float columns:\n",
      "durationinhours\n",
      "convert to Float columns:\n",
      "daynumberinpromotion\n",
      "convert to Float columns:\n",
      "bundleflag\n",
      "convert to Float columns:\n",
      "directdiscountflag\n",
      "convert to Float columns:\n",
      "freegiftflag\n",
      "convert to Float columns:\n",
      "suitflag\n",
      "convert to Float columns:\n",
      "stockprice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ow_train.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df_pred.replace('null', np.nan, inplace=True)\n",
      "ow_train.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df_pred.replace(-999, np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cart feature?\n",
      "False\n",
      "| Add date features...\n",
      "| - Add month of the year...\n",
      "| - Add day of the week...\n",
      "| Calculating national rolling features...\n",
      "('| - Rolling value:', 'xxxHashColumn')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 556.928106 seconds \n",
      "\n",
      "| Calculating  rolling features...\n",
      "('| - Rolling value:', 'OrderNonOutlierVolume')\n",
      "| - Rolling 360 mean...\n",
      "| - Rolling 180 mean...\n",
      "| - Rolling 90 mean...\n",
      "| - Rolling 28 mean...\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 360 mean...\n",
      "| - Rolling decay 180 mean...\n",
      "| - Rolling decay 90 mean...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 786.360955 seconds \n",
      "\n",
      "| Calculating similar rolling features...\n",
      "| - group by SyntheticPromotionSubType...\n",
      "| - process group: 1, code: 0.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 473.937077 seconds \n",
      "\n",
      "| - process group: 2, code: 11010.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 75.866935 seconds \n",
      "\n",
      "| - process group: 3, code: 11030.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.915911 seconds \n",
      "\n",
      "| - process group: 4, code: 100040.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 132.093447 seconds \n",
      "\n",
      "| - process group: 5, code: 11050.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 3.442848 seconds \n",
      "\n",
      "| - process group: 6, code: 100011.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 4.070712 seconds \n",
      "\n",
      "| - process group: 7, code: 10160.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 15.979409 seconds \n",
      "\n",
      "| - process group: 8, code: 10100.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 23.074102 seconds \n",
      "\n",
      "| - process group: 9, code: 100021.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 9.756745 seconds \n",
      "\n",
      "| - process group: 10, code: 100150.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 84.593908 seconds \n",
      "\n",
      "| - process group: 11, code: 100151.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.633050 seconds \n",
      "\n",
      "| - process group: 12, code: 10040.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 2.321166 seconds \n",
      "\n",
      "| - process group: 13, code: 100020.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 81.452546 seconds \n",
      "\n",
      "| - process group: 14, code: 100060.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 15.396155 seconds \n",
      "\n",
      "| - process group: 15, code: 100010.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 30.521359 seconds \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| - Added rolling features in 2603.361878 seconds \n",
      "\n",
      "| Calculating volume rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Shift 365...\n",
      "| - Shift 180...\n",
      "| - Shift 90...\n",
      "| - Shift 30...\n",
      "| - Shift 7...\n",
      "| - Added rolling features in 250.636723 seconds \n",
      "\n",
      "featuresDf shape\n",
      "(15902399, 141)\n",
      "rdc\n",
      "3\n",
      "rdc\n",
      "4\n",
      "rdc\n",
      "5\n",
      "rdc\n",
      "6\n",
      "rdc\n",
      "9\n",
      "rdc\n",
      "10\n",
      "rdc\n",
      "316\n",
      "rdc\n",
      "772\n"
     ]
    }
   ],
   "source": [
    "p1_out_path = os.path.join(result_path, 'train'+'_p1_'+str(cate)+'.csv')\n",
    "period_promo_raw = pd.read_csv(p1_out_path,parse_dates=['Date'])\n",
    "\n",
    "seasonality_df_train = seasonality_df.copy()\n",
    "ts_df_train = ts_df.copy()\n",
    "promoCalendarDf_train = promoCalendarDf.copy()\n",
    "\n",
    "model,feature=ow_train.train(area_rdc_map,period_promo_raw,promoCalendarDf_train,ts_df_train,scenario,holidays_df,seasonality_df_train,process_f01_flag=False,mode='dev',ForecastStartDate=pred_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.to_csv(os.path.join(result_path, str(cate)+'_train_feature.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model, os.path.join(result_path, str(cate)+'_train_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-04-18 00:00:00')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.Date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15902399, 141)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-02-01 00:00:00')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ow_predict.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df.replace('null', np.nan, inplace=True)\n",
      "ow_predict.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df.replace(-999, np.nan, inplace=True)\n",
      "ow_predict.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df.replace('None', np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Int columns:\n",
      "Holiday\n",
      "convert to Int columns:\n",
      "Ind_1111_pre\n",
      "convert to Int columns:\n",
      "Ind_1111\n",
      "convert to Int columns:\n",
      "Ind_1111_post\n",
      "convert to Int columns:\n",
      "Ind_618_pre\n",
      "convert to Int columns:\n",
      "Ind_618\n",
      "convert to Int columns:\n",
      "Ind_618_post\n",
      "convert to Int columns:\n",
      "Ind_1212\n",
      "convert to Float columns:\n",
      "MaxSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "MinSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "AvgSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "SyntheticGrossPrice\n",
      "convert to Float columns:\n",
      "promotionkey\n",
      "convert to Float columns:\n",
      "promotiontype\n",
      "convert to Float columns:\n",
      "promotionsubtype\n",
      "convert to Float columns:\n",
      "syntheticgrossprice_vb\n",
      "convert to Float columns:\n",
      "jdprice\n",
      "convert to Float columns:\n",
      "syntheticdiscounta_vb\n",
      "convert to Float columns:\n",
      "durationinhours\n",
      "convert to Float columns:\n",
      "daynumberinpromotion\n",
      "convert to Float columns:\n",
      "bundleflag\n",
      "convert to Float columns:\n",
      "directdiscountflag\n",
      "convert to Float columns:\n",
      "freegiftflag\n",
      "convert to Float columns:\n",
      "suitflag\n",
      "convert to Float columns:\n",
      "stockprice\n",
      "| Add date features...\n",
      "| - Add month of the year...\n",
      "| - Add day of the week...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code/refactor/common.py:1363: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  + df_past[similarLevels[2]]\n",
      "code/refactor/common.py:1364: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_past['SyntheticPromotionSubType'] = df_past['SyntheticPromotionSubType'].fillna(0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| - group by SyntheticPromotionSubType...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ow_predict.py:454: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  pred_df['ypred'] =ypred\n",
      "ow_predict.py:455: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  pred_df['RDCKey'] = rdc\n",
      "/home/ubuntu/lijingjie/ljj/local/lib/python2.7/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "p1_out_path = os.path.join(result_path, 'predict'+'_p1_'+str(cate)+'.csv')\n",
    "period_promo_raw = pd.read_csv(p1_out_path,parse_dates=['Date'])\n",
    "\n",
    "seasonality_df_test = seasonality_df.copy()\n",
    "ts_df_test = ts_df.copy()\n",
    "promoCalendarDf_test = promoCalendarDf.copy()\n",
    "\n",
    "# model_path = os.path.join(result_path, str(cate)+'/'+str(cate)+'_train_model.pkl')\n",
    "# with open(model_path,'r') as input:\n",
    "#     model = pickle.load(input)\n",
    "q_pred_result,df_fut=ow_predict.predict(area_rdc_map,period_promo_raw,promoCalendarDf_test,ts_df_test,scenario,holidays_df,model,seasonality_df_test,process_f01_flag=False,mode='dev',ForecastStartDate=pred_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict_mean.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df.replace('null', np.nan, inplace=True)\n",
      "predict_mean.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df.replace(-999, np.nan, inplace=True)\n",
      "predict_mean.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ts_df.replace('None', np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Float columns:\n",
      "RDCKey\n",
      "convert to Float columns:\n",
      "ProductKey\n",
      "convert to Float columns:\n",
      "HierarchyLevel1Key\n",
      "convert to Float columns:\n",
      "HierarchyLevel2Key\n",
      "convert to Float columns:\n",
      "HierarchyLevel3Key\n",
      "convert to Float columns:\n",
      "brand_code\n",
      "convert to Float columns:\n",
      "sales\n",
      "convert to Float columns:\n",
      "priceAfterDiscount\n",
      "convert to Float columns:\n",
      "jd_prc\n",
      "convert to Float columns:\n",
      "vendibility\n",
      "convert to Float columns:\n",
      "counterState\n",
      "convert to Float columns:\n",
      "salesForecast\n",
      "convert to Float columns:\n",
      "reserveState\n",
      "convert to Float columns:\n",
      "stockQuantity\n",
      "convert to Float columns:\n",
      "utc_flag\n",
      "convert to Int columns:\n",
      "Holiday\n",
      "convert to Int columns:\n",
      "Ind_1111_pre\n",
      "convert to Int columns:\n",
      "Ind_1111\n",
      "convert to Int columns:\n",
      "Ind_1111_post\n",
      "convert to Int columns:\n",
      "Ind_618_pre\n",
      "convert to Int columns:\n",
      "Ind_618\n",
      "convert to Int columns:\n",
      "Ind_618_post\n",
      "convert to Int columns:\n",
      "Ind_1212\n",
      "convert to Float columns:\n",
      "MaxSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "MinSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "AvgSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "SyntheticGrossPrice\n",
      "convert to Float columns:\n",
      "promotionkey\n",
      "convert to Float columns:\n",
      "promotiontype\n",
      "convert to Float columns:\n",
      "promotionsubtype\n",
      "convert to Float columns:\n",
      "syntheticgrossprice_vb\n",
      "convert to Float columns:\n",
      "jdprice\n",
      "convert to Float columns:\n",
      "syntheticdiscounta_vb\n",
      "convert to Float columns:\n",
      "durationinhours\n",
      "convert to Float columns:\n",
      "daynumberinpromotion\n",
      "convert to Float columns:\n",
      "bundleflag\n",
      "convert to Float columns:\n",
      "directdiscountflag\n",
      "convert to Float columns:\n",
      "freegiftflag\n",
      "convert to Float columns:\n",
      "suitflag\n",
      "| Add date features...\n",
      "| - Add month of the year...\n",
      "| - Add day of the week...\n",
      "| - group by SyntheticPromotionSubType...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict_mean.py:450: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  pred_df['ypred'] =ypred\n",
      "predict_mean.py:451: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  pred_df['RDCKey'] = rdc\n"
     ]
    }
   ],
   "source": [
    "p1_out_path = os.path.join(result_path, 'predict'+'_p1_'+str(cate)+'.csv')\n",
    "period_promo_raw = pd.read_csv(p1_out_path,parse_dates=['Date'])\n",
    "\n",
    "seasonality_df_mean = seasonality_df.copy()\n",
    "ts_df_mean = ts_df.copy()\n",
    "promoCalendarDf_mean = promoCalendarDf.copy()\n",
    "\n",
    "#train_feature_path = os.path.join(result_path, str(cate) + '/' + str(cate) + '_train_feature.csv')\n",
    "train_feature_df = feature\n",
    "q_mean_result,df_fut_mean=predict_mean.predict(area_rdc_map,period_promo_raw,promoCalendarDf,ts_df,scenario,holidays_df,model,seasonality_df,process_f01_flag=False,mode='dev',ForecastStartDate=pred_date,train_feature=train_feature_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ts_df = ts_df.copy()\n",
    "real_ts_df.columns = ['Date', 'ind', 'RDCKey', 'ProductKey', 'HierarchyLevel1Key', 'HierarchyLevel2Key', 'HierarchyLevel3Key', 'brand_code', 'sales', 'priceAfterDiscount', 'jd_prc', 'vendibility', 'counterState', 'salesForecast', 'reserveState', 'stockQuantity', 'utc_flag']\n",
    "real_ts_df['Date'] = pd.to_datetime(real_ts_df['Date'])\n",
    "simplified_ts_df = real_ts_df[real_ts_df.Date.between('2018-05-07','2018-05-13')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15902399 entries, 0 to 15902398\n",
      "Columns: 141 entries, Date to bd_discount_sgp_wgt\n",
      "dtypes: datetime64[ns](3), float64(121), int64(14), object(3)\n",
      "memory usage: 16.8+ GB\n"
     ]
    }
   ],
   "source": [
    "feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Memory usage of the dataframe is :', 17228, 'MB')\n",
      "**************************\n",
      "columns: HierarchyLevel1Key\n",
      "dtype before: int64\n",
      "dtype after: uint16\n",
      "********************************\n",
      "**************************\n",
      "columns: HierarchyLevel2Key\n",
      "dtype before: int64\n",
      "dtype after: uint16\n",
      "********************************\n",
      "**************************\n",
      "columns: HierarchyLevel3Key\n",
      "dtype before: int64\n",
      "dtype after: uint16\n",
      "********************************\n",
      "**************************\n",
      "columns: brand_code\n",
      "dtype before: int64\n",
      "dtype after: uint32\n",
      "********************************\n",
      "**************************\n",
      "columns: utc_flag\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Holiday\n",
      "dtype before: int64\n"
     ]
    }
   ],
   "source": [
    "train_feature_df = feature\n",
    "#model_path = 'tmp/data/shishang/' + str(cate) + '/' + str(cate) + '_train_model.pkl'\n",
    "\n",
    "df_new, NAlist = reduce_df_mem_usage(train_feature_df)\n",
    "\n",
    "ForecastStartDate = pd.to_datetime(pred_date)\n",
    "DataStartDate = ForecastStartDate - datetime.timedelta(days=scenario['lookbackPeriodDays'])\n",
    "PredictEndDate = ForecastStartDate + datetime.timedelta(days=(scenario['lookforwardPeriodDays']-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lijingjie/ljj/local/lib/python2.7/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "actual = simplified_ts_df\n",
    "actual.Date = pd.to_datetime(actual.Date)\n",
    "actual.RDCKey = actual.RDCKey.astype(float)\n",
    "\n",
    "list_keys = ['Date','RDCKey','ProductKey']\n",
    "\n",
    "raw = q_pred_result  ###bottomup forecast\n",
    "raw = raw[list_keys + ['salesForecast','ypred']]\n",
    "raw.rename(columns={'ypred':'ypred_raw'},inplace=True)\n",
    "raw.drop('salesForecast',axis=1,inplace=True)\n",
    "\n",
    "feat_cols = ['dd_price_weighted','bd_price_weighted','dd_price_weighted_x','bd_price_weighted_x','SyntheticGrossPrice']\n",
    "mean_df = q_mean_result\n",
    "mean_df = mean_df[list_keys + feat_cols + ['salesForecast','ypred']]\n",
    "mean_df.rename(columns={'ypred':'ypred_mean_promo'},inplace=True)\n",
    "mean_df.drop('salesForecast',axis=1,inplace=True)\n",
    "\n",
    "new_df = raw.merge(mean_df,on=list_keys)\n",
    "new_df.Date = pd.to_datetime(new_df.Date)\n",
    "new_df = pd.merge(new_df, actual[list_keys+['salesForecast']], how='left',on = list_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RDCKey</th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ypred_raw</th>\n",
       "      <th>dd_price_weighted</th>\n",
       "      <th>bd_price_weighted</th>\n",
       "      <th>dd_price_weighted_x</th>\n",
       "      <th>bd_price_weighted_x</th>\n",
       "      <th>SyntheticGrossPrice</th>\n",
       "      <th>ypred_mean_promo</th>\n",
       "      <th>salesForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>24.334154</td>\n",
       "      <td>153.427716</td>\n",
       "      <td>152.811594</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>22.588051</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>24.064211</td>\n",
       "      <td>153.427716</td>\n",
       "      <td>152.811594</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>21.853262</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>24.064211</td>\n",
       "      <td>153.427716</td>\n",
       "      <td>152.811594</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>21.853262</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>24.064211</td>\n",
       "      <td>153.427716</td>\n",
       "      <td>152.811594</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>21.853262</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>23.172569</td>\n",
       "      <td>153.427716</td>\n",
       "      <td>152.811594</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>22.669336</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  RDCKey ProductKey  ypred_raw  dd_price_weighted  \\\n",
       "0 2018-02-01     3.0     255778  24.334154         153.427716   \n",
       "1 2018-02-02     3.0     255778  24.064211         153.427716   \n",
       "2 2018-02-03     3.0     255778  24.064211         153.427716   \n",
       "3 2018-02-04     3.0     255778  24.064211         153.427716   \n",
       "4 2018-02-05     3.0     255778  23.172569         153.427716   \n",
       "\n",
       "   bd_price_weighted  dd_price_weighted_x  bd_price_weighted_x  \\\n",
       "0         152.811594                149.0                149.0   \n",
       "1         152.811594                149.0                149.0   \n",
       "2         152.811594                149.0                149.0   \n",
       "3         152.811594                149.0                149.0   \n",
       "4         152.811594                149.0                149.0   \n",
       "\n",
       "   SyntheticGrossPrice  ypred_mean_promo  salesForecast  \n",
       "0                149.0         22.588051           26.0  \n",
       "1                149.0         21.853262           29.0  \n",
       "2                149.0         21.853262           27.0  \n",
       "3                149.0         21.853262           21.0  \n",
       "4                149.0         22.669336           21.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclu_promo_features = ['strongmark','flashsale_ind','dd_ind','bundle_ind','bundle_buy199get100_ind','suit_ind','freegift_ind']\n",
    "update_cols = list(set(scenario['promo_feature_cols'])- set(exclu_promo_features))\n",
    "need_cols = ['Date','RDCKey','ProductKey','HierarchyLevel3Key'] + update_cols\n",
    "\n",
    "uses_promo = ['mean','no']\n",
    "df = df_new #df_new\n",
    "reg_cols = []#['Holiday','Ind_1111_pre','Ind_1111','Ind_1111_post','Ind_618_pre','Ind_618','Ind_618_post','Ind_1212','Month','DayOfWeek']\n",
    "#reg_cols = ['Holiday','Ind_1111_pre','Ind_1111','Ind_1111_post','Ind_618_pre','Ind_618','Ind_618_post','Ind_1212','Month','DayOfWeek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for use_promo in uses_promo:\n",
    "    if use_promo == 'mean':\n",
    "        df1 = df[need_cols]\n",
    "        groupkeys = ['RDCKey','ProductKey','HierarchyLevel3Key']\n",
    "        promo_feature_cols =  scenario['promo_feature_cols']\n",
    "        df11 = df1.groupby(groupkeys)[update_cols].mean().reset_index()\n",
    "        df2 = pd.merge(df,df11[groupkeys + update_cols], how='left',on=groupkeys)\n",
    "\n",
    "        rename_update_cols = [col+'_y' for col in update_cols]\n",
    "        for col in update_cols:\n",
    "            df2.rename(columns={col+'_y': col},inplace=True)\n",
    "            df2.drop(col+'_x',axis=1,inplace=True)\n",
    "        grouped = df2.groupby('RDCKey')\n",
    "    else:\n",
    "        #histoty bottomup forecast\n",
    "        grouped = df.groupby('RDCKey')\n",
    "    result_list = []\n",
    "    for rdc, history_df in grouped:\n",
    "        if rdc in model.keys():\n",
    "            this_model = model[rdc]\n",
    "        else:\n",
    "            continue\n",
    "        ''' predict model '''\n",
    "        xColumns = scenario['selectedColumns']['features']\n",
    "\n",
    "        if 'RDCKey' in xColumns:# ,RDCKEY\n",
    "            xColumns.remove('skuDecomposedTrend')\n",
    "            xColumns.remove('skuDecomposedSeasonal')\n",
    "            xColumns.remove('level3DecomposedTrend')\n",
    "            xColumns.remove('level3DecomposedSeasonal')\n",
    "            xColumns.remove('Curve')\n",
    "            xColumns.remove('RDCKey')\n",
    "        \n",
    "        X_history = history_df[xColumns]\n",
    "\n",
    "        history_xtest = xgb.DMatrix(X_history.values, missing=np.NaN )\n",
    "        ypred = this_model.predict(history_xtest)\n",
    "        history_df['ypred'] =ypred\n",
    "        history_df['RDCKey'] = rdc\n",
    "\n",
    "        ''' Tuning result '''\n",
    "        lanjie = history_df[(history_df.ypred<0)]\n",
    "        if len(lanjie)>0:\n",
    "            history_df.ix[lanjie.index,'ypred'] = 0\n",
    "        result_list.append(history_df)\n",
    "    final_result = pd.concat(result_list)\n",
    "    if use_promo == 'no':\n",
    "        raw_train_df = final_result[list_keys + reg_cols + scenario['promo_feature_cols'] + ['salesForecast','ypred']]\n",
    "    else:\n",
    "        #use_promo == 'mean':\n",
    "        train_df_mean = final_result[list_keys + reg_cols + scenario['promo_feature_cols'] + ['salesForecast','ypred']]\n",
    "        train_df_mean.rename(columns={'ypred':'ypred_mean_promo'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.merge(raw_train_df, train_df_mean[list_keys+['ypred_mean_promo']], how='left', on=list_keys)\n",
    "raw_test_df = q_pred_result\n",
    "raw_test_df = raw_test_df[list_keys + reg_cols + scenario['promo_feature_cols'] + ['salesForecast','ypred']]\n",
    "raw_test_df.Date = pd.to_datetime(raw_test_df.Date)\n",
    "\n",
    "used_cols = reg_cols + ['MaxSyntheticDiscountA']  #['MaxBundleDiscount','MaxDirectDiscount','MaxDiscount','MaxSyntheticDiscountA','daynumberinpromotion','PromotionCount']\n",
    "raw_train_df.Date = pd.to_datetime(raw_train_df.Date)\n",
    "raw_train_df = raw_train_df[raw_train_df.Date < pred_date]\n",
    "raw_train_df = raw_train_df[list_keys + reg_cols + scenario['promo_feature_cols'] + ['ypred','ypred_mean_promo']]\n",
    "input_df = pd.concat([raw_train_df, raw_test_df])\n",
    "\n",
    "for col in used_cols:\n",
    "    #input_df[col] = input_df.groupby(['RDCKey','ProductKey'])[col].transform(lambda x: x.fillna(method='bfill').fillna(0))\n",
    "    #input_df[col] = input_df.groupby(['RDCKey','ProductKey'])[col].transform(lambda x: x.fillna(method='ffill').fillna(0))\n",
    "    #input_df = input_df[input_df['MaxSyntheticDiscountA'].between(-1,1)]\n",
    "    \n",
    "    input_df = input_df[~(input_df[col].isnull())]\n",
    "    input_df = input_df[input_df[col].between(-1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "value_type = 'ypred_mean_promo'\n",
    "final_df = pd.DataFrame()\n",
    "a = 1\n",
    "grouped = input_df.groupby(['RDCKey','ProductKey'])\n",
    "for (rdc, sku), group in grouped:\n",
    "    if group.Date.min() < ForecastStartDate and group.Date.max() >= ForecastStartDate:\n",
    "        print a\n",
    "        a = a + 1\n",
    "        train_df = group[group.Date < ForecastStartDate]\n",
    "        test_df = group[group.Date >= ForecastStartDate]\n",
    "        x_train_df = train_df[used_cols]\n",
    "        x_test_df = test_df[used_cols]\n",
    "        \n",
    "        y_train = train_df['ypred'] - train_df[value_type]\n",
    "        y_test = test_df['salesForecast']\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(x_train_df, y_train)\n",
    "        Intercept = lm.intercept_\n",
    "        RSquare = lm.score(x_train_df, y_train)\n",
    "        lm_predict_result = lm.predict(x_test_df)\n",
    "        test_result = pd.DataFrame()\n",
    "        for col in list_keys+['salesForecast','ypred']:\n",
    "            test_result[col] = test_df[col]\n",
    "        test_result['reg_result'] = lm_predict_result\n",
    "\n",
    "        ###gaussian###\n",
    "        '''\n",
    "        if len(x_train_df[used_cols].drop_duplicates()) == 1:\n",
    "            test_result = pd.DataFrame()\n",
    "            for col in list_keys+['salesForecast','ypred']:\n",
    "                test_result[col] = test_df[col]\n",
    "            test_result['reg_result'] = y_train.tail().mean()\n",
    "        else:\n",
    "            lm = make_pipeline(GaussianFeatures(5), Lasso(alpha=0.1))\n",
    "            lm.fit(np.array(x_train_df), np.array(y_train))\n",
    "            Intercept = lm.steps[1][1].intercept_\n",
    "            RSquare = lm.score(np.array(x_train_df), np.array(y_train))\n",
    "            lm_predict_result = lm.predict(np.array(x_test_df))\n",
    "            test_result = pd.DataFrame()\n",
    "            for col in list_keys+['salesForecast','ypred']:\n",
    "                test_result[col] = test_df[col]\n",
    "            test_result['reg_result'] = lm_predict_result\n",
    "        '''\n",
    "        ###polynomial###\n",
    "        '''\n",
    "        pf = PolynomialFeatures(degree=2)\n",
    "        pModel = LinearRegression()\n",
    "        pModel.fit(pf.fit_transform(x_train_df), y_train)\n",
    "        pf_predict_result = pModel.predict(pf.fit_transform(x_test_df))\n",
    "        test_result = pd.DataFrame()\n",
    "        for col in list_keys+['salesForecast','ypred']:\n",
    "            test_result[col] = test_df[col]\n",
    "        test_result['reg_result'] = pf_predict_result\n",
    "        '''\n",
    "        final_df = pd.concat([final_df, test_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_final = final_df\n",
    "mean_final.rename(columns={'reg_result':'mean_promo_reg_result'},inplace=True)\n",
    "final_df.drop('salesForecast',axis=1,inplace=True)\n",
    "final_df.drop('ypred',axis=1,inplace=True)\n",
    "new_df_final = new_df.merge(final_df,on=list_keys,how='left')\n",
    "new_df_final.fillna(0,inplace=True)\n",
    "new_df_final['ypred_mean_promo_new'] = new_df_final['ypred_mean_promo'] + new_df_final['mean_promo_reg_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RDCKey</th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ypred_raw</th>\n",
       "      <th>ypred_mean_promo</th>\n",
       "      <th>salesForecast</th>\n",
       "      <th>mean_promo_reg_result</th>\n",
       "      <th>ypred_mean_promo_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193952</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193952</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193952</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193952</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193952</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  RDCKey  ProductKey  ypred_raw  ypred_mean_promo  salesForecast  \\\n",
       "0  2018-04-01     3.0      193952   0.000785          0.000785            0.0   \n",
       "1  2018-04-02     3.0      193952   0.000785          0.000785            0.0   \n",
       "2  2018-04-03     3.0      193952   0.000785          0.000785            0.0   \n",
       "3  2018-04-04     3.0      193952   0.000785          0.000785            0.0   \n",
       "4  2018-04-05     3.0      193952   0.000785          0.000785            0.0   \n",
       "\n",
       "   mean_promo_reg_result  ypred_mean_promo_new  \n",
       "0                    0.0              0.000785  \n",
       "1                    0.0              0.000785  \n",
       "2                    0.0              0.000785  \n",
       "3                    0.0              0.000785  \n",
       "4                    0.0              0.000785  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_final = pd.read_csv('./result_btup_lr/result_ensemble_2589.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble pred sum : 39110.941565\n",
      "raw pred sum :      40378.883483\n",
      "actual sum:         37386.000000\n",
      "raw pred residual:      16524.768977\n",
      "ensemble pred residual: 15053.484354\n",
      "raw pred mape: 0.442004\n",
      "ensemble mape: 0.402650\n"
     ]
    }
   ],
   "source": [
    "new_df_sku = new_df_final.groupby('ProductKey').sum().reset_index()\n",
    "print \"ensemble pred sum : %f\"%(new_df_sku.ypred_mean_promo_new.sum())\n",
    "print \"raw pred sum :      %f\"%(new_df_sku.ypred_raw.sum())\n",
    "print \"actual sum:         %f\"%(new_df_sku.salesForecast.sum())\n",
    "\n",
    "print \"raw pred residual:      %f\"%(np.sum(np.abs(new_df_sku.ypred_raw - new_df_sku.salesForecast)))\n",
    "print \"ensemble pred residual: %f\"%(np.sum(np.abs(new_df_sku.ypred_mean_promo_new - new_df_sku.salesForecast)))\n",
    "\n",
    "print \"raw pred mape: %f\"%(np.sum(np.abs(new_df_sku.ypred_raw - new_df_sku.salesForecast)) / new_df_sku.salesForecast.sum())\n",
    "print \"ensemble mape: %f\"%(np.sum(np.abs(new_df_sku.ypred_mean_promo_new - new_df_sku.salesForecast)) / new_df_sku.salesForecast.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
