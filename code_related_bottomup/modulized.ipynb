{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "import os.path\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import ow_f01, cxmn_train, cxmn_predict, predict_mean\n",
    "from code.refactor.common import loadSettingsFromYamlFile,save_object,object2Float,get_column_by_type\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_used_header = ['productkey', 'promotionkey', 'startdatetime', 'enddatetime', 'jdprice', 'syntheticgrossprice', 'promotiondesc', 'promotiondesc_flag', 'promotiontype', 'promotionsubtype',\n",
    "                'areatypearray', 'tokenflag', 'directdiscount_discount', 'directdiscount_availabilitynumber', 'bundle_subtype1_threshold', 'bundle_subtype1_giveaway',\n",
    "                'bundle_subtype4_threshold1', 'bundle_subtype4_giveaway1', 'bundle_subtype4_threshold2', 'bundle_subtype4_giveaway2', 'bundle_subtype4_threshold3',\n",
    "                'bundle_subtype4_giveaway3', 'bundle_subtype2_threshold', 'bundle_subtype2_giveaway', 'bundle_subtype2_maximumgiveaway', 'bundle_subtype15_thresholdnumber1',\n",
    "                'bundle_subtype15_giveawayrate1', 'bundle_subtype15_thresholdnumber2', 'bundle_subtype15_giveawayrate2', 'bundle_subtype15_thresholdnumber3',\n",
    "                'bundle_subtype15_giveawayrate3', 'bundle_subtype6_thresholdnumber', 'bundle_subtype6_freenumber', 'suit_maxvaluepool', 'suit_minvaluepool', 'suit_avgvaluepool',\n",
    "                'suit_discount', 'directdiscount_saleprice', 'bundle_subtype1_percent', 'bundle_subtype4_percent', 'bundle_subtype2_percent', 'bundle_subtype15_percent',\n",
    "                'bundle_subtype6_percent', 'suit_percent', 'allpercentdiscount', 'mainproductkey', 'hierarchylevel3key', 'createdate', 'statuscode', 'dt']\n",
    "p2_used_header = ['ProductKey', 'Date', 'HierarchyLevel3Key', 'PromotionCount', 'bundlecount', 'MaxDiscount', 'MinDiscount', 'AvgDiscount', 'MaxSyntheticDiscountA',\n",
    "\t\t\t\t         'MinSyntheticDiscountA', 'AvgSyntheticDiscountA', 'MaxBundleDiscount', 'MinBundleDiscount', 'AvgBundleDiscount', 'MaxDirectDiscount', 'MinDirectDiscount',\n",
    "\t\t\t\t         'AvgDirectDiscount', 'MaxFreegiftDiscount', 'MinFreegiftDiscount', 'AvgFreegiftDiscount', 'SyntheticGrossPrice', 'promotionkey', 'promotiontype',\n",
    "\t\t\t\t         'promotionsubtype', 'syntheticgrossprice_vb', 'jdprice', 'syntheticdiscounta_vb', 'durationinhours', 'daynumberinpromotion', 'bundleflag', 'directdiscountflag',\n",
    "\t\t\t\t         'freegiftflag', 'suitflag', 'numberproducts', 'numberhierarchylevel1', 'numberhierarchylevel2', 'numberhierarchylevel3', 'strongmark', 'stockprice', 'dt']\n",
    "suffix = '.da'\n",
    "item = 'p1'\n",
    "for_what = ['train', 'predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Uniformly spaced Gaussian features for one-dimensional input\"\"\"\n",
    "\n",
    "    def __init__(self, N, width_factor=2.0):\n",
    "        self.N = N\n",
    "        self.width_factor = width_factor\n",
    "\n",
    "    @staticmethod\n",
    "    def _gauss_basis(x, y, width, axis=None):\n",
    "        arg = (x - y) / width\n",
    "        return np.exp(-0.5 * np.sum(arg ** 2, axis))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # create N centers spread along the data range\n",
    "        self.centers_ = np.linspace(X.min(), X.max(), self.N)\n",
    "        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._gauss_basis(X[:, :, np.newaxis], self.centers_,\n",
    "                                 self.width_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df_mem_usage(df):\n",
    "    # memery now\n",
    "    start_mem_usg = df.memory_usage().sum() / 1024 ** 2\n",
    "    print(\"Memory usage of the dataframe is :\", start_mem_usg, \"MB\")\n",
    "    \n",
    "    #np.nan will be handled as float\n",
    "    NAlist = []\n",
    "    for col in df.columns:\n",
    "        # filter object type\n",
    "        if (df[col].dtypes == np.float64):\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "            continue\n",
    "        if (df[col].dtypes != object)&(df[col].dtypes != 'datetime64[ns]'):\n",
    "            \n",
    "            print(\"**************************\")\n",
    "            print(\"columns: %s\"%col)\n",
    "            print(\"dtype before: %s\"%df[col].dtype)\n",
    "            \n",
    "            # if int or not\n",
    "            isInt = False\n",
    "            mmax = df[col].max()\n",
    "            mmin = df[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore Na needs to be filled\n",
    "            if not np.isfinite(df[col]).all():\n",
    "                NAlist.append(col)\n",
    "                #continue\n",
    "                df[col].fillna(-999, inplace=True) # fill -999\n",
    "                \n",
    "            # test if column can be converted to an integer\n",
    "            asint = df[col].fillna(0).astype(np.int64)\n",
    "            result = np.fabs(df[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result < 0.01: # absolute error < 0.01,then could be saw as integer\n",
    "                isInt = True\n",
    "            \n",
    "            # make interger / unsigned Integer datatypes\n",
    "            if isInt:\n",
    "                if mmin >= 0: # min>=0, then unsigned integer\n",
    "                    if mmax <= np.iinfo(np.uint8).max:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif mmax <= np.iinfo(np.uint16).max:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif mmax <= np.iinfo(np.uint32).max:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mmin > np.iinfo(np.int8).min and mmax < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif mmin > np.iinfo(np.int16).min and mmax < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif mmin > np.iinfo(np.int32).min and mmax < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif mmin > np.iinfo(np.int64).min and mmax < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "            df.replace(-999, np.nan, inplace=True)\n",
    "            print(\"dtype after: %s\"%df[col].dtype)\n",
    "            print(\"********************************\")\n",
    "    print(\"___MEMORY USAGE AFTER CONVERSION:___\")\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statitics_mape(new_df_final):\n",
    "\t\tnew_df_sku = new_df_final.groupby('ProductKey').sum().reset_index()\n",
    "\t\tprint \"ensemble pred sum : %f\"%(new_df_sku.ypred_mean_promo_new.sum())\n",
    "\t\tprint \"raw pred sum :      %f\"%(new_df_sku.ypred_raw.sum())\n",
    "\t\tprint \"actual sum:         %f\"%(new_df_sku.salesForecast.sum())\n",
    "\n",
    "\t\tprint \"raw pred residual:      %f\"%(np.sum(np.abs(new_df_sku.ypred_raw - new_df_sku.salesForecast)))\n",
    "\t\tprint \"ensemble pred residual: %f\"%(np.sum(np.abs(new_df_sku.ypred_mean_promo_new - new_df_sku.salesForecast)))\n",
    "\n",
    "\t\tprint \"raw pred mape: %f\"%(np.sum(np.abs(new_df_sku.ypred_raw - new_df_sku.salesForecast)) / new_df_sku.salesForecast.sum())\n",
    "\t\tprint \"ensemble mape: %f\"%(np.sum(np.abs(new_df_sku.ypred_mean_promo_new - new_df_sku.salesForecast)) / new_df_sku.salesForecast.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_history_data():\n",
    "    p1 = pd.read_csv('/home/ubuntu/sunjiadong/promotion_offline/tmp/data/7054_p1.da', sep='\\t', header=None)\n",
    "    p2 = pd.read_csv('/home/ubuntu/sunjiadong/promotion_offline/tmp/data/7054_p2.da', sep='\\t', header=None)\n",
    "    ts = pd.read_csv('/home/ubuntu/sunjiadong/promotion_offline/tmp/data/7054_ts.da', sep='\\t', header=None)\n",
    "    \n",
    "    # p1 = pd.read_csv('/home/ubuntu/sunjiadong/promotion_offline/tmp/data/shishang/12029/12029_p1.da',sep='\\t',header=None)\n",
    "    # p2 = pd.read_csv('/home/ubuntu/sunjiadong/promotion_offline/tmp/data/shishang/12029/12029_p2.da',sep='\\t',header=None)\n",
    "    # ts = pd.read_csv('/home/ubuntu/sunjiadong/promotion_offline/tmp/data/shishang/12029/12029_ts.da',sep='\\t',header=None)\n",
    "    return p1,p2,ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarioSettingsPath = 'code/refactor/ow_scenario.yaml'\n",
    "scenario = loadSettingsFromYamlFile(scenarioSettingsPath)\n",
    "area_rdc_map = pd.read_csv('/home/ubuntu/yulong/promotion_offline/tmp/ow_deploy_single/area_rdc_mapping.csv')\n",
    "holidays_df=pd.read_csv('/home/ubuntu/yulong/promotion_offline/tmp/ow_deploy_single/holidays.csv')\n",
    "seasonality_df = pd.read_csv('tmp/data/870_season.csv', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = 7054\n",
    "pred_date = pd.to_datetime('2018-02-01')\n",
    "scenario['lookforwardPeriodDays'] = 10\n",
    "\n",
    "#cate = 12029\n",
    "#pred_date = pd.to_datetime('2018-05-07')\n",
    "#scenario['lookforwardPeriodDays'] = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_df,p2_df,ts_df = get_online_history_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42150 entries, 0 to 42149\n",
      "Data columns (total 40 columns):\n",
      "0     42150 non-null int64\n",
      "1     42150 non-null object\n",
      "2     42150 non-null int64\n",
      "3     42150 non-null int64\n",
      "4     42150 non-null int64\n",
      "5     42150 non-null float64\n",
      "6     42150 non-null float64\n",
      "7     42150 non-null float64\n",
      "8     42150 non-null object\n",
      "9     42150 non-null object\n",
      "10    42150 non-null object\n",
      "11    42150 non-null float64\n",
      "12    42150 non-null float64\n",
      "13    42150 non-null float64\n",
      "14    42150 non-null float64\n",
      "15    42150 non-null float64\n",
      "16    42150 non-null float64\n",
      "17    42150 non-null float64\n",
      "18    42150 non-null float64\n",
      "19    42150 non-null float64\n",
      "20    42150 non-null object\n",
      "21    42150 non-null object\n",
      "22    42150 non-null object\n",
      "23    42150 non-null object\n",
      "24    42150 non-null object\n",
      "25    42150 non-null object\n",
      "26    42150 non-null object\n",
      "27    42150 non-null object\n",
      "28    42150 non-null object\n",
      "29    42150 non-null object\n",
      "30    42150 non-null object\n",
      "31    42150 non-null object\n",
      "32    42150 non-null object\n",
      "33    42150 non-null int64\n",
      "34    42150 non-null int64\n",
      "35    42150 non-null int64\n",
      "36    42150 non-null int64\n",
      "37    42150 non-null int64\n",
      "38    42150 non-null float64\n",
      "39    42150 non-null object\n",
      "dtypes: float64(13), int64(9), object(18)\n",
      "memory usage: 43.2 MB\n"
     ]
    }
   ],
   "source": [
    "p2_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_df.columns = p1_used_header\n",
    "p2_df.columns = p2_used_header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Float columns:\n",
      "MaxSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "MinSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "AvgSyntheticDiscountA\n",
      "convert to Float columns:\n",
      "SyntheticGrossPrice\n",
      "convert to Float columns:\n",
      "promotionkey\n",
      "convert to Float columns:\n",
      "promotiontype\n",
      "convert to Float columns:\n",
      "promotionsubtype\n",
      "convert to Float columns:\n",
      "syntheticgrossprice_vb\n",
      "convert to Float columns:\n",
      "jdprice\n",
      "convert to Float columns:\n",
      "syntheticdiscounta_vb\n",
      "convert to Float columns:\n",
      "durationinhours\n",
      "convert to Float columns:\n",
      "daynumberinpromotion\n",
      "convert to Float columns:\n",
      "bundleflag\n",
      "convert to Float columns:\n",
      "directdiscountflag\n",
      "convert to Float columns:\n",
      "freegiftflag\n",
      "convert to Float columns:\n",
      "suitflag\n"
     ]
    }
   ],
   "source": [
    "###handle p2\n",
    "p2_df['Date'] = pd.to_datetime(p2_df['Date'])\n",
    "p2_df['dt'] = pd.to_datetime(p2_df['dt'])\n",
    "p2_df.replace('null', np.nan, inplace=True)\n",
    "p2_df.replace('None', np.nan, inplace=True)\n",
    "p2_df.replace(-999, np.nan, inplace=True)\n",
    "p2_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert Object -> float\n",
    "if 'object' in p2_df.dtypes.values:\n",
    "    obj_cols = get_column_by_type(p2_df,'object')\n",
    "    object2Float(p2_df,obj_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42150 entries, 0 to 42149\n",
      "Data columns (total 40 columns):\n",
      "ProductKey                42150 non-null int64\n",
      "Date                      42150 non-null datetime64[ns]\n",
      "HierarchyLevel3Key        42150 non-null int64\n",
      "PromotionCount            42150 non-null int64\n",
      "bundlecount               42150 non-null int64\n",
      "MaxDiscount               42150 non-null float64\n",
      "MinDiscount               42150 non-null float64\n",
      "AvgDiscount               42150 non-null float64\n",
      "MaxSyntheticDiscountA     34264 non-null float64\n",
      "MinSyntheticDiscountA     34264 non-null float64\n",
      "AvgSyntheticDiscountA     34264 non-null float64\n",
      "MaxBundleDiscount         42150 non-null float64\n",
      "MinBundleDiscount         42150 non-null float64\n",
      "AvgBundleDiscount         42150 non-null float64\n",
      "MaxDirectDiscount         42150 non-null float64\n",
      "MinDirectDiscount         42150 non-null float64\n",
      "AvgDirectDiscount         42150 non-null float64\n",
      "MaxFreegiftDiscount       42150 non-null float64\n",
      "MinFreegiftDiscount       42150 non-null float64\n",
      "AvgFreegiftDiscount       42150 non-null float64\n",
      "SyntheticGrossPrice       34264 non-null float64\n",
      "promotionkey              15713 non-null float64\n",
      "promotiontype             15713 non-null float64\n",
      "promotionsubtype          15713 non-null float64\n",
      "syntheticgrossprice_vb    15713 non-null float64\n",
      "jdprice                   15713 non-null float64\n",
      "syntheticdiscounta_vb     15713 non-null float64\n",
      "durationinhours           15713 non-null float64\n",
      "daynumberinpromotion      15713 non-null float64\n",
      "bundleflag                15713 non-null float64\n",
      "directdiscountflag        15713 non-null float64\n",
      "freegiftflag              15713 non-null float64\n",
      "suitflag                  15713 non-null float64\n",
      "numberproducts            42150 non-null int64\n",
      "numberhierarchylevel1     42150 non-null int64\n",
      "numberhierarchylevel2     42150 non-null int64\n",
      "numberhierarchylevel3     42150 non-null int64\n",
      "strongmark                42150 non-null int64\n",
      "stockprice                42150 non-null float64\n",
      "dt                        42150 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(29), int64(9)\n",
      "memory usage: 13.2 MB\n"
     ]
    }
   ],
   "source": [
    "p2_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output and save: 7054_p1_train\n",
      "convert to Float columns:\n",
      "allpercentdiscount\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate1\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate2\n",
      "convert to Float columns:\n",
      "bundle_subtype15_giveawayrate3\n",
      "convert to Float columns:\n",
      "bundle_subtype15_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber1\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber2\n",
      "convert to Float columns:\n",
      "bundle_subtype15_thresholdnumber3\n",
      "convert to Float columns:\n",
      "bundle_subtype1_giveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype1_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype1_threshold\n",
      "convert to Float columns:\n",
      "bundle_subtype2_giveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype2_maximumgiveaway\n",
      "convert to Float columns:\n",
      "bundle_subtype2_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype2_threshold\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway1\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway2\n",
      "convert to Float columns:\n",
      "bundle_subtype4_giveaway3\n",
      "convert to Float columns:\n",
      "bundle_subtype4_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold1\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold2\n",
      "convert to Float columns:\n",
      "bundle_subtype4_threshold3\n",
      "convert to Float columns:\n",
      "bundle_subtype6_freenumber\n",
      "convert to Float columns:\n",
      "bundle_subtype6_percent\n",
      "convert to Float columns:\n",
      "bundle_subtype6_thresholdnumber\n",
      "convert to Float columns:\n",
      "directdiscount_availabilitynumber\n",
      "convert to Float columns:\n",
      "directdiscount_discount\n",
      "convert to Float columns:\n",
      "directdiscount_saleprice\n",
      "convert to Float columns:\n",
      "hierarchylevel3key\n",
      "convert to Float columns:\n",
      "jdprice\n",
      "convert to Float columns:\n",
      "mainproductkey\n",
      "convert to Float columns:\n",
      "productkey\n",
      "convert to Float columns:\n",
      "promotionkey\n",
      "convert to Float columns:\n",
      "promotionsubtype\n",
      "convert to Float columns:\n",
      "promotiontype\n",
      "convert to Float columns:\n",
      "statuscode\n",
      "convert to Float columns:\n",
      "suit_avgvaluepool\n",
      "convert to Float columns:\n",
      "suit_discount\n",
      "convert to Float columns:\n",
      "suit_maxvaluepool\n",
      "convert to Float columns:\n",
      "suit_minvaluepool\n",
      "convert to Float columns:\n",
      "suit_percent\n",
      "convert to Float columns:\n",
      "syntheticgrossprice\n",
      "('| - Before filter: ', 51610)\n",
      "('| - Filtered tokens: ', 48511)\n",
      "('| - Filtered descriptions: ', 48511)\n",
      "('| - Filtered flash sale available units', 47446)\n",
      "('| - Filtered non-national promo: ', 45238)\n",
      "| | - Add additional columns\n",
      "| | - Calculate dd price per promotion\n",
      "| | - Calculate dd price per period\n",
      "| | - Generate bundle features\n",
      "| | - Calculate bundle price per period\n",
      "| - Reformat date\n",
      "| | - process features\n",
      "| | - aggregate features per period\n",
      "| | - prep data for Step 3\n",
      "| | - fix indicators on days with end time 00:00 or start time 23:59\n",
      "| | - calculate weighted price per day\n",
      "| | - aggregate features per day\n",
      "f01 shape\n",
      "(76155, 23)\n",
      "output and save: 7054_p1_predict\n",
      "('| - Before filter: ', 3283)\n",
      "('| - Filtered tokens: ', 3186)\n",
      "('| - Filtered descriptions: ', 3186)\n",
      "('| - Filtered flash sale available units', 3171)\n",
      "('| - Filtered non-national promo: ', 3157)\n",
      "| | - Add additional columns\n",
      "| | - Calculate dd price per promotion\n",
      "| | - Calculate dd price per period\n",
      "| | - Generate bundle features\n",
      "| | - Calculate bundle price per period\n",
      "| - Reformat date\n",
      "| | - process features\n",
      "| | - aggregate features per period\n",
      "| | - prep data for Step 3\n",
      "| | - fix indicators on days with end time 00:00 or start time 23:59\n",
      "| | - calculate weighted price per day\n",
      "| | - aggregate features per day\n",
      "f01 shape\n",
      "(21902, 23)\n"
     ]
    }
   ],
   "source": [
    "def handle_f01(p1_df, for_what, area_rdc_map, pred_date, scenario):\n",
    "    for fw in for_what:\n",
    "    \tprint \"output and save: %s_p1_%s\"%(str(cate),fw)\n",
    "    \ttrain_pred_gate = fw   # 'train'\n",
    "    \tf01_output = ow_f01.generate_f01_promo(area_rdc_map, p1_df, scenario, train_pred_gate, ForecastStartDate=pred_date)\n",
    "    \tif train_pred_gate == 'train':\n",
    "    \t\ttrain_p1_df = f01_output\n",
    "    \telse:\n",
    "    \t\tpredict_p1_df = f01_output\n",
    "    return train_p1_df, predict_p1_df\n",
    "train_p1_df,predict_p1_df = handle_f01(p1_df, for_what, area_rdc_map, pred_date, scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76155, 23)\n",
      "(21902, 23)\n"
     ]
    }
   ],
   "source": [
    "print train_p1_df.shape\n",
    "print predict_p1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Float columns:\n",
      "RDCKey\n",
      "convert to Float columns:\n",
      "ProductKey\n",
      "convert to Float columns:\n",
      "HierarchyLevel1Key\n",
      "convert to Float columns:\n",
      "HierarchyLevel2Key\n",
      "convert to Float columns:\n",
      "HierarchyLevel3Key\n",
      "convert to Float columns:\n",
      "brand_code\n",
      "convert to Float columns:\n",
      "sales\n",
      "convert to Float columns:\n",
      "priceAfterDiscount\n",
      "convert to Float columns:\n",
      "jd_prc\n",
      "convert to Float columns:\n",
      "vendibility\n",
      "convert to Float columns:\n",
      "counterState\n",
      "convert to Float columns:\n",
      "salesForecast\n",
      "convert to Float columns:\n",
      "reserveState\n",
      "convert to Float columns:\n",
      "stockQuantity\n",
      "convert to Float columns:\n",
      "utc_flag\n"
     ]
    }
   ],
   "source": [
    "ts_df.columns = ['Date', 'ind', 'RDCKey', 'ProductKey', 'HierarchyLevel1Key', 'HierarchyLevel2Key', 'HierarchyLevel3Key', 'brand_code', 'sales', 'priceAfterDiscount', 'jd_prc', 'vendibility', 'counterState', 'salesForecast', 'reserveState', 'stockQuantity', 'utc_flag']\n",
    "ts_df['Date'] = pd.to_datetime(ts_df['Date'])\n",
    "\n",
    "ts_df.replace('null', np.nan, inplace=True)\n",
    "ts_df.replace(-999, np.nan, inplace=True)\n",
    "ts_df.replace('None', np.nan, inplace=True)\n",
    "ts_to_float_col = ['RDCKey', 'ProductKey', 'HierarchyLevel1Key', 'HierarchyLevel2Key', 'HierarchyLevel3Key', 'brand_code', 'sales', 'priceAfterDiscount', 'jd_prc', 'vendibility', 'counterState', 'salesForecast', 'reserveState', 'stockQuantity', 'utc_flag']\n",
    "if 'object' in ts_df[ts_to_float_col].dtypes.values:\n",
    "    object2Float(ts_df,ts_to_float_col)\n",
    "levels = ['HierarchyLevel3Key','ProductKey','RDCKey','Date']\n",
    "ts_df.sort_values(levels, ascending=[True]*len(levels), inplace=True)\n",
    "ts_df= ts_df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972720 entries, 0 to 972719\n",
      "Data columns (total 17 columns):\n",
      "Date                  972720 non-null datetime64[ns]\n",
      "ind                   972720 non-null int64\n",
      "RDCKey                972720 non-null float64\n",
      "ProductKey            972720 non-null float64\n",
      "HierarchyLevel1Key    972720 non-null float64\n",
      "HierarchyLevel2Key    972720 non-null float64\n",
      "HierarchyLevel3Key    972720 non-null float64\n",
      "brand_code            972720 non-null float64\n",
      "sales                 972720 non-null float64\n",
      "priceAfterDiscount    228354 non-null float64\n",
      "jd_prc                228354 non-null float64\n",
      "vendibility           972720 non-null float64\n",
      "counterState          972720 non-null float64\n",
      "salesForecast         972720 non-null float64\n",
      "reserveState          972720 non-null float64\n",
      "stockQuantity         972720 non-null float64\n",
      "utc_flag              972720 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(15), int64(1)\n",
      "memory usage: 126.2 MB\n"
     ]
    }
   ],
   "source": [
    "ts_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Int columns:\n",
      "Holiday\n",
      "convert to Int columns:\n",
      "Ind_1111_pre\n",
      "convert to Int columns:\n",
      "Ind_1111\n",
      "convert to Int columns:\n",
      "Ind_1111_post\n",
      "convert to Int columns:\n",
      "Ind_618_pre\n",
      "convert to Int columns:\n",
      "Ind_618\n",
      "convert to Int columns:\n",
      "Ind_618_post\n",
      "convert to Int columns:\n",
      "Ind_1212\n",
      "use cart feature?\n",
      "False\n",
      "| Add date features...\n",
      "| - Add month of the year...\n",
      "| - Add day of the week...\n",
      "| Calculating national rolling features...\n",
      "('| - Rolling value:', 'xxxHashColumn')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 10.030496 seconds \n",
      "\n",
      "| Calculating  rolling features...\n",
      "('| - Rolling value:', 'OrderNonOutlierVolume')\n",
      "| - Rolling 360 mean...\n",
      "| - Rolling 180 mean...\n",
      "| - Rolling 90 mean...\n",
      "| - Rolling 28 mean...\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 360 mean...\n",
      "| - Rolling decay 180 mean...\n",
      "| - Rolling decay 90 mean...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 20.122120 seconds \n",
      "\n",
      "| Calculating similar rolling features...\n",
      "| - group by SyntheticPromotionSubType...\n",
      "| - process group: 1, code: 0.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 8.053281 seconds \n",
      "\n",
      "| - process group: 2, code: 11010.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 2.095544 seconds \n",
      "\n",
      "| - process group: 3, code: 11030.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 0.814147 seconds \n",
      "\n",
      "| - process group: 4, code: 100040.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 2.820642 seconds \n",
      "\n",
      "| - process group: 5, code: 11050.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.397549 seconds \n",
      "\n",
      "| - process group: 6, code: 100011.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.145249 seconds \n",
      "\n",
      "| - process group: 7, code: 10160.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 4.721218 seconds \n",
      "\n",
      "| - process group: 8, code: 100020.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 0.920346 seconds \n",
      "\n",
      "| - process group: 9, code: 100021.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 0.961749 seconds \n",
      "\n",
      "| - process group: 10, code: 100150.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.219478 seconds \n",
      "\n",
      "| - process group: 11, code: 11060.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.291096 seconds \n",
      "\n",
      "| - process group: 12, code: 10100.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.482038 seconds \n",
      "\n",
      "| - process group: 13, code: 100060.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.023209 seconds \n",
      "\n",
      "| - process group: 14, code: 100010.0...\n",
      "| Calculating similar rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Rolling 14 mean...\n",
      "| - Rolling 7 mean...\n",
      "| - Rolling 5 mean...\n",
      "| - Rolling 3 mean...\n",
      "| - Rolling 2 mean...\n",
      "| - Rolling 1 mean...\n",
      "| - Rolling 14 median...\n",
      "| - Rolling 7 median...\n",
      "| - Rolling decay 28 mean...\n",
      "| - Rolling decay 14 mean...\n",
      "| - Rolling decay 7 mean...\n",
      "| - Rolling decay 3 mean...\n",
      "| - Added rolling features in 1.395246 seconds \n",
      "\n",
      "| - Added rolling features in 36.924015 seconds \n",
      "\n",
      "| Calculating volume rolling features...\n",
      "('| - Rolling value:', 'salesForecast')\n",
      "| - Shift 365...\n",
      "| - Shift 180...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| - Shift 90...\n",
      "| - Shift 30...\n",
      "| - Shift 7...\n",
      "| - Added rolling features in 2.164192 seconds \n",
      "\n",
      "featuresDf shape\n",
      "(213245, 141)\n",
      "rdc\n",
      "3.0\n",
      "rdc\n",
      "4.0\n",
      "rdc\n",
      "5.0\n",
      "rdc\n",
      "6.0\n",
      "rdc\n",
      "9.0\n",
      "rdc\n",
      "10.0\n",
      "rdc\n",
      "316.0\n",
      "rdc\n",
      "772.0\n"
     ]
    }
   ],
   "source": [
    "def train_model(area_rdc_map, train_p1_df, p2_df, ts_df, scenario, holidays_df, seasonality_df, pred_date):\n",
    "\tseasonality_df_train = seasonality_df.copy()\n",
    "\tmodel,feature=cxmn_train.train(area_rdc_map,train_p1_df,p2_df,ts_df,scenario,holidays_df,seasonality_df_train,process_f01_flag=False,mode='dev',ForecastStartDate=pred_date)\n",
    "\t#feature.to_csv(os.path.join(result_path, str(cate)+'/'+str(cate)+'_train_feature.csv'),index=False)\n",
    "\t#save_object(model, os.path.join(result_path, str(cate)+'/'+str(cate)+'_train_model.pkl'))\n",
    "\treturn model, feature\n",
    "model, feature = train_model(area_rdc_map, train_p1_df, p2_df, ts_df, scenario, holidays_df, seasonality_df, pred_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Int columns:\n",
      "Holiday\n",
      "convert to Int columns:\n",
      "Ind_1111_pre\n",
      "convert to Int columns:\n",
      "Ind_1111\n",
      "convert to Int columns:\n",
      "Ind_1111_post\n",
      "convert to Int columns:\n",
      "Ind_618_pre\n",
      "convert to Int columns:\n",
      "Ind_618\n",
      "convert to Int columns:\n",
      "Ind_618_post\n",
      "convert to Int columns:\n",
      "Ind_1212\n",
      "| Add date features...\n",
      "| - Add month of the year...\n",
      "| - Add day of the week...\n",
      "| - group by SyntheticPromotionSubType...\n"
     ]
    }
   ],
   "source": [
    "def predict_q_pred(area_rdc_map, predict_p1_df, p2_df, ts_df, scenario, holidays_df, seasonality_df, pred_date, model):\n",
    "\tseasonality_df_test = seasonality_df.copy()\n",
    "\tq_pred_result,df_fut=cxmn_predict.predict(area_rdc_map,predict_p1_df,p2_df,ts_df,scenario,holidays_df,model,seasonality_df_test,process_f01_flag=False,mode='dev',ForecastStartDate=pred_date)\n",
    "\t#q_pred_result.to_csv('tmp/data/test_0705/'+'result_'+str(cate)+'.csv',index=False)\n",
    "\treturn q_pred_result, df_fut\n",
    "q_pred_result, df_fut = predict_q_pred(area_rdc_map, predict_p1_df, p2_df, ts_df, scenario, holidays_df, seasonality_df, pred_date, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 213245 entries, 0 to 213244\n",
      "Columns: 141 entries, Date to bd_discount_sgp_wgt\n",
      "dtypes: datetime64[ns](3), float64(127), int64(10), object(1)\n",
      "memory usage: 235.9 MB\n"
     ]
    }
   ],
   "source": [
    "feature.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df_new = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Memory usage of the dataframe is :', 231, 'MB')\n",
      "**************************\n",
      "columns: Holiday\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Ind_1111_pre\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Ind_1111\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Ind_1111_post\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Ind_618_pre\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Ind_618\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Ind_618_post\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Ind_1212\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: Month\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "**************************\n",
      "columns: DayOfWeek\n",
      "dtype before: int64\n",
      "dtype after: uint8\n",
      "********************************\n",
      "___MEMORY USAGE AFTER CONVERSION:___\n",
      "('Memory usage is: ', 113, ' MB')\n",
      "('This is ', 48, '% of the initial size')\n"
     ]
    }
   ],
   "source": [
    "train_feature_df_new = reduce_df_mem_usage(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to Int columns:\n",
      "Holiday\n",
      "convert to Int columns:\n",
      "Ind_1111_pre\n",
      "convert to Int columns:\n",
      "Ind_1111\n",
      "convert to Int columns:\n",
      "Ind_1111_post\n",
      "convert to Int columns:\n",
      "Ind_618_pre\n",
      "convert to Int columns:\n",
      "Ind_618\n",
      "convert to Int columns:\n",
      "Ind_618_post\n",
      "convert to Int columns:\n",
      "Ind_1212\n",
      "| Add date features...\n",
      "| - Add month of the year...\n",
      "| - Add day of the week...\n",
      "| - group by SyntheticPromotionSubType...\n"
     ]
    }
   ],
   "source": [
    "def predict_q_mean(area_rdc_map, predict_p1_df, p2_df, ts_df, scenario, holidays_df, seasonality_df, pred_date, model, train_feature_df_new):\n",
    "\tseasonality_df_mean = seasonality_df.copy()\n",
    "\tq_mean_result,df_fut_mean = predict_mean.predict(area_rdc_map,predict_p1_df,p2_df,ts_df,scenario,holidays_df,model,seasonality_df_mean,process_f01_flag=False,mode='dev',ForecastStartDate=pred_date,train_feature=train_feature_df_new)\n",
    "\t#q_mean_result.to_csv('tmp/data/shishang/result/'+'result_'+str(cate)+'_mean.csv',index=False)\n",
    "\treturn q_mean_result, df_fut_mean\n",
    "q_mean_result, df_fut_mean = predict_q_mean(area_rdc_map, predict_p1_df, p2_df, ts_df, scenario, holidays_df, seasonality_df, pred_date, model, train_feature_df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_sales(ts_df, pred_date, scenario):\n",
    "\tsimplified_ts_df = ts_df[ts_df.Date.between(pred_date, pd.to_datetime(pred_date)+\\\n",
    "                       pd.DateOffset(days=scenario['lookforwardPeriodDays']-1))]\n",
    "\treturn simplified_ts_df\n",
    "simplified_ts_df = get_actual_sales(ts_df, pred_date, scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_ts_df.ProductKey\t.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ForecastStartDate = pd.to_datetime(pred_date)\n",
    "DataStartDate = ForecastStartDate - datetime.timedelta(days=scenario['lookbackPeriodDays'])\n",
    "PredictEndDate = ForecastStartDate + datetime.timedelta(days=(scenario['lookforwardPeriodDays']-1))\n",
    "\n",
    "actual = simplified_ts_df\n",
    "actual.Date = pd.to_datetime(actual.Date)\n",
    "actual.RDCKey = actual.RDCKey.astype(float)\n",
    "\n",
    "list_keys = ['Date','RDCKey','ProductKey']\n",
    "feat_cols = ['dd_price_weighted','bd_price_weighted','dd_price_weighted_x','bd_price_weighted_x','SyntheticGrossPrice']\n",
    "exclu_promo_features = ['strongmark','flashsale_ind','dd_ind','bundle_ind','bundle_buy199get100_ind','suit_ind','freegift_ind']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "def get_raw_test_df(raw_pred, mean_pred, keys, feat_cols):\n",
    "\n",
    "\traw = raw_pred  ###bottomup forecast\n",
    "\traw = raw[keys + ['salesForecast','ypred']]\n",
    "\traw.rename(columns={'ypred':'ypred_raw'},inplace=True)\n",
    "\traw.drop('salesForecast',axis=1,inplace=True)\n",
    "\n",
    "\tmean_df = mean_pred\n",
    "\tmean_df = mean_df[keys + feat_cols + ['salesForecast','ypred']]\n",
    "\tmean_df.rename(columns={'ypred':'ypred_mean_promo'},inplace=True)\n",
    "\tmean_df.drop('salesForecast',axis=1,inplace=True)\n",
    "\n",
    "\tnew_df = raw.merge(mean_df,on=list_keys)\n",
    "\tnew_df.Date = pd.to_datetime(new_df.Date)\n",
    "\tnew_df = pd.merge(new_df, actual[list_keys+['salesForecast']], how='left',on = list_keys)\n",
    "\n",
    "\treturn new_df\n",
    "new_df = get_raw_test_df(q_pred_result, q_mean_result, list_keys, feat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RDCKey</th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ypred_raw</th>\n",
       "      <th>dd_price_weighted</th>\n",
       "      <th>bd_price_weighted</th>\n",
       "      <th>dd_price_weighted_x</th>\n",
       "      <th>bd_price_weighted_x</th>\n",
       "      <th>SyntheticGrossPrice</th>\n",
       "      <th>ypred_mean_promo</th>\n",
       "      <th>salesForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>20.571106</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.8116</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>20.921082</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.8116</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>20.921082</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.8116</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>20.921082</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.8116</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778</td>\n",
       "      <td>23.651291</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.8116</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>13.065337</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  RDCKey ProductKey  ypred_raw  dd_price_weighted  \\\n",
       "0 2018-02-01     3.0     255778  20.571106         153.427719   \n",
       "1 2018-02-02     3.0     255778  20.921082         153.427719   \n",
       "2 2018-02-03     3.0     255778  20.921082         153.427719   \n",
       "3 2018-02-04     3.0     255778  20.921082         153.427719   \n",
       "4 2018-02-05     3.0     255778  23.651291         153.427719   \n",
       "\n",
       "   bd_price_weighted  dd_price_weighted_x  bd_price_weighted_x  \\\n",
       "0           152.8116                149.0                149.0   \n",
       "1           152.8116                149.0                149.0   \n",
       "2           152.8116                149.0                149.0   \n",
       "3           152.8116                149.0                149.0   \n",
       "4           152.8116                149.0                149.0   \n",
       "\n",
       "   SyntheticGrossPrice  ypred_mean_promo  salesForecast  \n",
       "0                149.0         10.873569           26.0  \n",
       "1                149.0         10.873569           29.0  \n",
       "2                149.0         10.873569           27.0  \n",
       "3                149.0         10.873569           21.0  \n",
       "4                149.0         13.065337           21.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_cols = list(set(scenario['promo_feature_cols'])- set(exclu_promo_features))\n",
    "need_cols = ['Date','RDCKey','ProductKey','HierarchyLevel3Key'] + update_cols\n",
    "groupkeys = ['RDCKey','ProductKey','HierarchyLevel3Key']\n",
    "reg_cols = []#['Holiday','Ind_1111_pre','Ind_1111','Ind_1111_post','Ind_618_pre','Ind_618','Ind_618_post','Ind_1212','Month','DayOfWeek',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def predict_history_mean_and_raw(train_feature_df_new, reg_cols,listkeys, keys, model, update_cols, scenario):\n",
    "\tuses_promo = ['mean','no']\n",
    "\tdf = train_feature_df_new\n",
    "\tfor use_promo in uses_promo:\n",
    "\t    if use_promo == 'mean':\n",
    "\t        df1 = df[need_cols]\n",
    "\t        promo_feature_cols =  scenario['promo_feature_cols']\n",
    "\t        df11 = df1.groupby(keys)[update_cols].mean().reset_index()\n",
    "\t        df2 = pd.merge(df,df11[keys + update_cols], how='left',on=keys)\n",
    "\n",
    "\t        rename_update_cols = [col+'_y' for col in update_cols]\n",
    "\t        for col in update_cols:\n",
    "\t            df2.rename(columns={col+'_y': col},inplace=True)\n",
    "\t            df2.drop(col+'_x',axis=1,inplace=True)\n",
    "\t        grouped = df2.groupby('RDCKey')\n",
    "\t    else:\n",
    "\t        #histoty bottomup forecast\n",
    "\t        grouped = df.groupby('RDCKey')\n",
    "\t    result_list = []\n",
    "\t    for rdc, history_df in grouped:\n",
    "\t        if rdc in model.keys():\n",
    "\t            this_model = model[rdc]\n",
    "\t        else:\n",
    "\t            continue\n",
    "\t        ''' predict model '''\n",
    "\t        xColumns = scenario['selectedColumns']['features']\n",
    "\n",
    "\t        if 'RDCKey' in xColumns:# ,RDCKEY\n",
    "\t            xColumns.remove('skuDecomposedTrend')\n",
    "\t            xColumns.remove('skuDecomposedSeasonal')\n",
    "\t            xColumns.remove('level3DecomposedTrend')\n",
    "\t            xColumns.remove('level3DecomposedSeasonal')\n",
    "\t            xColumns.remove('Curve')\n",
    "\t            xColumns.remove('RDCKey')\n",
    "\t        \n",
    "\t        X_history = history_df[xColumns]\n",
    "\n",
    "\t        history_xtest = xgb.DMatrix(X_history.values, missing=np.NaN )\n",
    "\t        ypred = this_model.predict(history_xtest)\n",
    "\t        history_df['ypred'] =ypred\n",
    "\t        history_df['RDCKey'] = rdc\n",
    "\n",
    "\t        ''' Tuning result '''\n",
    "\t        lanjie = history_df[(history_df.ypred<0)]\n",
    "\t        if len(lanjie)>0:\n",
    "\t            history_df.ix[lanjie.index,'ypred'] = 0\n",
    "\t        result_list.append(history_df)\n",
    "\t    final_result = pd.concat(result_list)\n",
    "\t    if use_promo == 'no':\n",
    "\t        raw_train_df = final_result[listkeys + reg_cols + scenario['promo_feature_cols'] + ['salesForecast','ypred']]\n",
    "\t    else:\n",
    "\t        #use_promo == 'mean':\n",
    "\t        train_df_mean = final_result[listkeys + reg_cols + scenario['promo_feature_cols'] + ['salesForecast','ypred']]\n",
    "\t        train_df_mean.rename(columns={'ypred':'ypred_mean_promo'}, inplace=True)\n",
    "\treturn raw_train_df, train_df_mean\n",
    "raw_train_df, train_df_mean = predict_history_mean_and_raw(train_feature_df_new, reg_cols, list_keys, groupkeys, model, update_cols, scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-02-10 00:00:00')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_pred_result.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.merge(raw_train_df, train_df_mean[list_keys+['ypred_mean_promo']], how='left', on=list_keys)\n",
    "raw_test_df = q_pred_result\n",
    "raw_test_df = raw_test_df[list_keys + reg_cols + scenario['promo_feature_cols'] + ['salesForecast','ypred']]\n",
    "raw_test_df.Date = pd.to_datetime(raw_test_df.Date)\n",
    "\n",
    "used_cols = reg_cols + ['MaxSyntheticDiscountA']  #['MaxBundleDiscount','MaxDirectDiscount','MaxDiscount','MaxSyntheticDiscountA','daynumberinpromotion','PromotionCount']\n",
    "raw_train_df.Date = pd.to_datetime(raw_train_df.Date)\n",
    "raw_train_df = raw_train_df[raw_train_df.Date < pred_date]\n",
    "raw_train_df = raw_train_df[list_keys + reg_cols + scenario['promo_feature_cols'] + ['ypred','ypred_mean_promo']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.concat([raw_train_df, raw_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lr_cols(input_df, cols):\n",
    "\tfor col in cols:\n",
    "\t    #input_df[col] = input_df.groupby(['RDCKey','ProductKey'])[col].transform(lambda x: x.fillna(method='bfill').fillna(0))\n",
    "\t    #input_df[col] = input_df.groupby(['RDCKey','ProductKey'])[col].transform(lambda x: x.fillna(method='ffill').fillna(0))\n",
    "\t    #input_df = input_df[input_df['MaxSyntheticDiscountA'].between(-1,1)]\n",
    "\t    \n",
    "\t    input_df = input_df[~(input_df[col].isnull())]\n",
    "\t    input_df = input_df[input_df[col].between(-1,1)]\n",
    "        return input_df\n",
    "\n",
    "input_df = process_lr_cols(input_df, used_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "def lr_promo_simulate(input_df, start_dt, used_cols, listkeys):\n",
    "\tvalue_type = 'ypred_mean_promo'\n",
    "\tfinal_df = pd.DataFrame()\n",
    "\ta = 1\n",
    "\tgrouped = input_df.groupby(['RDCKey','ProductKey'])\n",
    "\tfor (rdc, sku), group in grouped:\n",
    "\t    if group.Date.min() < start_dt and group.Date.max() >= start_dt:\n",
    "\t        print a\n",
    "\t        a = a + 1\n",
    "\t        train_df = group[group.Date < start_dt]\n",
    "\t        test_df = group[group.Date >= start_dt]\n",
    "\t        x_train_df = train_df[used_cols]\n",
    "\t        x_test_df = test_df[used_cols]\n",
    "\t        \n",
    "\t        y_train = train_df['ypred'] - train_df[value_type]\n",
    "\t        y_test = test_df['salesForecast']\n",
    "\t        lm = LinearRegression()\n",
    "\t        lm.fit(x_train_df, y_train)\n",
    "\t        Intercept = lm.intercept_\n",
    "\t        RSquare = lm.score(x_train_df, y_train)\n",
    "\t        lm_predict_result = lm.predict(x_test_df)\n",
    "\t        test_result = pd.DataFrame()\n",
    "\t        for col in listkeys+['salesForecast','ypred']:\n",
    "\t            test_result[col] = test_df[col]\n",
    "\t        test_result['reg_result'] = lm_predict_result\n",
    "\n",
    "\t        ###gaussian###\n",
    "\t        '''\n",
    "\t        if len(x_train_df[used_cols].drop_duplicates()) == 1:\n",
    "\t            test_result = pd.DataFrame()\n",
    "\t            for col in list_keys+['salesForecast','ypred']:\n",
    "\t                test_result[col] = test_df[col]\n",
    "\t            test_result['reg_result'] = y_train.tail().mean()\n",
    "\t        else:\n",
    "\t            lm = make_pipeline(GaussianFeatures(5), Lasso(alpha=0.1))\n",
    "\t            lm.fit(np.array(x_train_df), np.array(y_train))\n",
    "\t            Intercept = lm.steps[1][1].intercept_\n",
    "\t            RSquare = lm.score(np.array(x_train_df), np.array(y_train))\n",
    "\t            lm_predict_result = lm.predict(np.array(x_test_df))\n",
    "\t            test_result = pd.DataFrame()\n",
    "\t            for col in list_keys+['salesForecast','ypred']:\n",
    "\t                test_result[col] = test_df[col]\n",
    "\t            test_result['reg_result'] = lm_predict_result\n",
    "\t        '''\n",
    "\t        ###polynomial###\n",
    "\t        '''\n",
    "\t        pf = PolynomialFeatures(degree=2)\n",
    "\t        pModel = LinearRegression()\n",
    "\t        pModel.fit(pf.fit_transform(x_train_df), y_train)\n",
    "\t        pf_predict_result = pModel.predict(pf.fit_transform(x_test_df))\n",
    "\t        test_result = pd.DataFrame()\n",
    "\t        for col in list_keys+['salesForecast','ypred']:\n",
    "\t            test_result[col] = test_df[col]\n",
    "\t        test_result['reg_result'] = pf_predict_result\n",
    "\t        '''\n",
    "\t        final_df = pd.concat([final_df, test_result])\n",
    "\treturn final_df\n",
    "\n",
    "final_df = lr_promo_simulate(input_df, ForecastStartDate, used_cols, list_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-02-09 00:00:00')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-02-01 00:00:00')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.Date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.ProductKey.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_final = final_df\n",
    "mean_final.rename(columns={'reg_result':'mean_promo_reg_result'},inplace=True)\n",
    "final_df.drop('salesForecast',axis=1,inplace=True)\n",
    "final_df.drop('ypred',axis=1,inplace=True)\n",
    "new_df_final = new_df.merge(final_df,on=list_keys,how='left')\n",
    "new_df_final.fillna(0,inplace=True)\n",
    "new_df_final['ypred_mean_promo_new'] = new_df_final['ypred_mean_promo'] + new_df_final['mean_promo_reg_result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RDCKey</th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ypred_raw</th>\n",
       "      <th>dd_price_weighted</th>\n",
       "      <th>bd_price_weighted</th>\n",
       "      <th>dd_price_weighted_x</th>\n",
       "      <th>bd_price_weighted_x</th>\n",
       "      <th>SyntheticGrossPrice</th>\n",
       "      <th>ypred_mean_promo</th>\n",
       "      <th>salesForecast</th>\n",
       "      <th>mean_promo_reg_result</th>\n",
       "      <th>ypred_mean_promo_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>20.571106</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.858400</td>\n",
       "      <td>12.731970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>20.921082</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.858400</td>\n",
       "      <td>12.731970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>20.921082</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.858400</td>\n",
       "      <td>12.731970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>20.921082</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>10.873569</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.858400</td>\n",
       "      <td>12.731970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>23.651291</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>13.065337</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.858400</td>\n",
       "      <td>14.923737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>24.609684</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>13.376189</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.858400</td>\n",
       "      <td>15.234589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>20.990210</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>11.292673</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.858400</td>\n",
       "      <td>13.151073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>23.995256</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>158.0</td>\n",
       "      <td>12.735791</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.896542</td>\n",
       "      <td>14.632333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>25.687412</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>158.0</td>\n",
       "      <td>12.735791</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.896542</td>\n",
       "      <td>14.632333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-02-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255778.0</td>\n",
       "      <td>31.010353</td>\n",
       "      <td>153.427719</td>\n",
       "      <td>152.811600</td>\n",
       "      <td>49.6667</td>\n",
       "      <td>49.6667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.494842</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.494842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>13.998791</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>60.3334</td>\n",
       "      <td>60.3334</td>\n",
       "      <td>65.0</td>\n",
       "      <td>12.447107</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.184088</td>\n",
       "      <td>13.631195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>16.947662</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>58.0000</td>\n",
       "      <td>58.0000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>15.395979</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.184088</td>\n",
       "      <td>16.580067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>2.364878</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>58.6668</td>\n",
       "      <td>58.6668</td>\n",
       "      <td>59.9</td>\n",
       "      <td>0.227691</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.728508</td>\n",
       "      <td>0.956199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>3.549026</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.227691</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.828616</td>\n",
       "      <td>1.056307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>1.988736</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.044656</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.248351</td>\n",
       "      <td>1.293007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>2.063905</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.885815</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.538483</td>\n",
       "      <td>1.424298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>2.278079</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.044656</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.538483</td>\n",
       "      <td>1.583139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>1.545750</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.654747</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.538483</td>\n",
       "      <td>2.193230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>1.545750</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.654747</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.538483</td>\n",
       "      <td>2.193230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-02-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>255780.0</td>\n",
       "      <td>1.545750</td>\n",
       "      <td>63.574295</td>\n",
       "      <td>61.514774</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.654747</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.654747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-02-10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333373.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>64.748688</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  RDCKey  ProductKey  ypred_raw  dd_price_weighted  \\\n",
       "0  2018-02-01     3.0    255778.0  20.571106         153.427719   \n",
       "1  2018-02-02     3.0    255778.0  20.921082         153.427719   \n",
       "2  2018-02-03     3.0    255778.0  20.921082         153.427719   \n",
       "3  2018-02-04     3.0    255778.0  20.921082         153.427719   \n",
       "4  2018-02-05     3.0    255778.0  23.651291         153.427719   \n",
       "5  2018-02-06     3.0    255778.0  24.609684         153.427719   \n",
       "6  2018-02-07     3.0    255778.0  20.990210         153.427719   \n",
       "7  2018-02-08     3.0    255778.0  23.995256         153.427719   \n",
       "8  2018-02-09     3.0    255778.0  25.687412         153.427719   \n",
       "9  2018-02-10     3.0    255778.0  31.010353         153.427719   \n",
       "10 2018-02-01     3.0    255780.0  13.998791          63.574295   \n",
       "11 2018-02-02     3.0    255780.0  16.947662          63.574295   \n",
       "12 2018-02-03     3.0    255780.0   2.364878          63.574295   \n",
       "13 2018-02-04     3.0    255780.0   3.549026          63.574295   \n",
       "14 2018-02-05     3.0    255780.0   1.988736          63.574295   \n",
       "15 2018-02-06     3.0    255780.0   2.063905          63.574295   \n",
       "16 2018-02-07     3.0    255780.0   2.278079          63.574295   \n",
       "17 2018-02-08     3.0    255780.0   1.545750          63.574295   \n",
       "18 2018-02-09     3.0    255780.0   1.545750          63.574295   \n",
       "19 2018-02-10     3.0    255780.0   1.545750          63.574295   \n",
       "20 2018-02-01     3.0    333373.0   0.015822          64.748688   \n",
       "21 2018-02-02     3.0    333373.0   0.015822          64.748688   \n",
       "22 2018-02-03     3.0    333373.0   0.015822          64.748688   \n",
       "23 2018-02-04     3.0    333373.0   0.015822          64.748688   \n",
       "24 2018-02-05     3.0    333373.0   0.015822          64.748688   \n",
       "25 2018-02-06     3.0    333373.0   0.015822          64.748688   \n",
       "26 2018-02-07     3.0    333373.0   0.015822          64.748688   \n",
       "27 2018-02-08     3.0    333373.0   0.015822          64.748688   \n",
       "28 2018-02-09     3.0    333373.0   0.015822          64.748688   \n",
       "29 2018-02-10     3.0    333373.0   0.015822          64.748688   \n",
       "\n",
       "    bd_price_weighted  dd_price_weighted_x  bd_price_weighted_x  \\\n",
       "0          152.811600             149.0000             149.0000   \n",
       "1          152.811600             149.0000             149.0000   \n",
       "2          152.811600             149.0000             149.0000   \n",
       "3          152.811600             149.0000             149.0000   \n",
       "4          152.811600             149.0000             149.0000   \n",
       "5          152.811600             149.0000             149.0000   \n",
       "6          152.811600             149.0000             149.0000   \n",
       "7          152.811600             149.0000             149.0000   \n",
       "8          152.811600             149.0000             149.0000   \n",
       "9          152.811600              49.6667              49.6667   \n",
       "10          61.514774              60.3334              60.3334   \n",
       "11          61.514774              58.0000              58.0000   \n",
       "12          61.514774              58.6668              58.6668   \n",
       "13          61.514774              63.0000              63.0000   \n",
       "14          61.514774              65.0000              65.0000   \n",
       "15          61.514774              65.0000              65.0000   \n",
       "16          61.514774              65.0000              65.0000   \n",
       "17          61.514774              65.0000              65.0000   \n",
       "18          61.514774              65.0000              65.0000   \n",
       "19          61.514774              65.0000              65.0000   \n",
       "20          64.748688              70.0000              70.0000   \n",
       "21          64.748688              70.0000              70.0000   \n",
       "22          64.748688              70.0000              70.0000   \n",
       "23          64.748688              70.0000              70.0000   \n",
       "24          64.748688              70.0000              70.0000   \n",
       "25          64.748688              70.0000              70.0000   \n",
       "26          64.748688              70.0000              70.0000   \n",
       "27          64.748688              70.0000              70.0000   \n",
       "28          64.748688              70.0000              70.0000   \n",
       "29          64.748688              70.0000              70.0000   \n",
       "\n",
       "    SyntheticGrossPrice  ypred_mean_promo  salesForecast  \\\n",
       "0                 149.0         10.873569           26.0   \n",
       "1                 149.0         10.873569           29.0   \n",
       "2                 149.0         10.873569           27.0   \n",
       "3                 149.0         10.873569           21.0   \n",
       "4                 149.0         13.065337           21.0   \n",
       "5                 149.0         13.376189           26.0   \n",
       "6                 149.0         11.292673           19.0   \n",
       "7                 158.0         12.735791           22.0   \n",
       "8                 158.0         12.735791            8.0   \n",
       "9                   0.0         12.494842           21.0   \n",
       "10                 65.0         12.447107            3.0   \n",
       "11                 65.0         15.395979            6.0   \n",
       "12                 59.9          0.227691            3.0   \n",
       "13                 62.0          0.227691            6.0   \n",
       "14                 62.0          1.044656            7.0   \n",
       "15                 65.0          0.885815            8.0   \n",
       "16                 65.0          1.044656           14.0   \n",
       "17                 65.0          1.654747            9.0   \n",
       "18                 65.0          1.654747            8.0   \n",
       "19                  0.0          1.654747            2.0   \n",
       "20                  0.0          0.015822            0.0   \n",
       "21                  0.0          0.015822            0.0   \n",
       "22                  0.0          0.015822            0.0   \n",
       "23                  0.0          0.015822            0.0   \n",
       "24                  0.0          0.015822            0.0   \n",
       "25                  0.0          0.015822            0.0   \n",
       "26                  0.0          0.015822            0.0   \n",
       "27                  0.0          0.015822            0.0   \n",
       "28                  0.0          0.015822            0.0   \n",
       "29                  0.0          0.015822            0.0   \n",
       "\n",
       "    mean_promo_reg_result  ypred_mean_promo_new  \n",
       "0                1.858400             12.731970  \n",
       "1                1.858400             12.731970  \n",
       "2                1.858400             12.731970  \n",
       "3                1.858400             12.731970  \n",
       "4                1.858400             14.923737  \n",
       "5                1.858400             15.234589  \n",
       "6                1.858400             13.151073  \n",
       "7                1.896542             14.632333  \n",
       "8                1.896542             14.632333  \n",
       "9                0.000000             12.494842  \n",
       "10               1.184088             13.631195  \n",
       "11               1.184088             16.580067  \n",
       "12               0.728508              0.956199  \n",
       "13               0.828616              1.056307  \n",
       "14               0.248351              1.293007  \n",
       "15               0.538483              1.424298  \n",
       "16               0.538483              1.583139  \n",
       "17               0.538483              2.193230  \n",
       "18               0.538483              2.193230  \n",
       "19               0.000000              1.654747  \n",
       "20               0.000000              0.015822  \n",
       "21               0.000000              0.015822  \n",
       "22               0.000000              0.015822  \n",
       "23               0.000000              0.015822  \n",
       "24               0.000000              0.015822  \n",
       "25               0.000000              0.015822  \n",
       "26               0.000000              0.015822  \n",
       "27               0.000000              0.015822  \n",
       "28               0.000000              0.015822  \n",
       "29               0.000000              0.015822  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_final.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble pred sum : 17671.093899\n",
      "raw pred sum :      19411.119141\n",
      "actual sum:         21034.000000\n",
      "raw pred residual:      6840.980298\n",
      "ensemble pred residual: 7643.863663\n",
      "raw pred mape: 0.325234\n",
      "ensemble mape: 0.363405\n"
     ]
    }
   ],
   "source": [
    "statitics_mape(new_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble pred sum : 19398.550781\n",
      "raw pred sum :      20388.822266\n",
      "actual sum:         21034.000000\n",
      "raw pred residual:      5530.731600\n",
      "ensemble pred residual: 5372.254739\n",
      "raw pred mape: 0.262942\n",
      "ensemble mape: 0.255408\n"
     ]
    }
   ],
   "source": [
    "statitics_mape(new_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4779,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_final.ProductKey.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
