{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "import os.path\n",
    "from code.refactor.common import (get_setting_from_cfg, get_setting_path, filter_df_by_cate_id,get_future_sales_feature,\\\n",
    "                                  dummy_features, model_predict, get_weekly_df,get_future_condition_sales_feature,gen_train_valid_by_date,\\\n",
    "                                  generate_promotion_future, get_hour, save_object, add_pv,get_lowest_n,generate_cv_train_valid_set,\\\n",
    "                                  generate_default_values_by_dic,fill_col_with_default, week2month,trans_band_to_int,get_future_condition_sales_feature_stage2,\\\n",
    "                                  loadSettingsFromYamlFile,createSeasonalityFeatures,createLevel3Features,createSeasonalityDecomposeFeatures,\\\n",
    "                                 calculateNationalRolling_predict,calculateRolling_predict,calculateLagging_predict,createDateFeatures,splitTimeWindow,calculateSimilarRolling_predict,calculateStockFeatures,\\\n",
    "                                 process_rdc,clean_data,add_cols,get_dd_price,agg_dd_price,get_bundle_feat,agg_bd_price,process_feature,\\\n",
    "                                 agg_feature,prep_data,calc_weighted_price,agg_feature_day,get_column_by_type,object2Float,object2Int)\n",
    "from code.refactor.fdc_flow import  filter_non_price_fill_it\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "scenarioSettingsPath = 'code/refactor/ow_scenario.yaml'\n",
    "scenario = loadSettingsFromYamlFile(scenarioSettingsPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = 870\n",
    "df = pd.read_csv('./tmp/data/0425_result/' + str(cate) + '_train_feature.csv')\n",
    "model_path = 'tmp/data/0425_result/' + str(cate) + '_train_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path,'r') as input:\n",
    "    model = pickle.load(input)\n",
    "\n",
    "exclu_promo_features = ['strongmark','flashsale_ind','dd_ind','bundle_ind','bundle_buy199get100_ind','suit_ind','freegift_ind']\n",
    "update_cols = list(set(scenario['promo_feature_cols'])- set(exclu_promo_features))\n",
    "need_cols = ['Date','RDCKey','ProductKey','HierarchyLevel3Key'] + update_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use promotion mean\n",
    "df1 = df[need_cols]\n",
    "groupkeys = ['RDCKey','ProductKey','HierarchyLevel3Key']\n",
    "promo_feature_cols =  scenario['promo_feature_cols']\n",
    "df11 = df1.groupby(groupkeys)[update_cols].mean().reset_index()\n",
    "df2 = pd.merge(df,df11[groupkeys + update_cols], how='left',on=groupkeys)\n",
    "\n",
    "pd.options.display.max_columns=999\n",
    "pd.options.display.max_rows=999\n",
    "pd.options.display.width=160\n",
    "\n",
    "rename_update_cols = [col+'_y' for col in update_cols]\n",
    "for col in update_cols:\n",
    "    df2.rename(columns={col+'_y': col},inplace=True)\n",
    "grouped = df2.groupby('RDCKey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use promotoin 0\n",
    "for col in update_cols:\n",
    "  df[col] = 0\n",
    "grouped = df.groupby('RDCKey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histoty bottomup forecast\n",
    "grouped = df.groupby('RDCKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/lijingjie/ljj/lib/python2.7/site-packages/ipykernel_launcher.py:30: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "for rdc, history_df in grouped:\n",
    "    if rdc in model.keys():\n",
    "        this_model = model[rdc]\n",
    "    else:\n",
    "        continue\n",
    "    ''' predict model '''\n",
    "    xColumns = scenario['selectedColumns']['features']\n",
    "\n",
    "    if 'RDCKey' in xColumns:# 删除季节性,RDCKEY\n",
    "        #xColumns.remove('skuDecomposedTrend')\n",
    "        #xColumns.remove('skuDecomposedSeasonal')\n",
    "        #xColumns.remove('level3DecomposedTrend')\n",
    "        #xColumns.remove('level3DecomposedSeasonal')\n",
    "        #xColumns.remove('Curve')\n",
    "        xColumns.remove('RDCKey')\n",
    "        #for col in update_cols: ###sjd_update\n",
    "        #    xColumns.remove(col)\n",
    "\n",
    "    X_history = history_df[xColumns]\n",
    "\n",
    "    history_xtest = xgb.DMatrix(X_history.values, missing=np.NaN )\n",
    "    ypred = this_model.predict(history_xtest)\n",
    "    history_df['ypred'] =ypred\n",
    "    history_df['RDCKey'] = rdc\n",
    "\n",
    "    ''' Tuning result '''\n",
    "    lanjie = history_df[(history_df.ypred<0)]\n",
    "    if len(lanjie)>0:\n",
    "        history_df.ix[lanjie.index,'ypred'] = 0\n",
    "    result_list.append(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.concat(result_list)\n",
    "final_result.to_csv('./tmp/data/0425_result/history_' + str(cate) + '_sales.csv',index=False)\n",
    "#final_result.to_csv('./tmp/data/0425_result/history_7052_sales_promo_zero.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395075, 142)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
